{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>機械学習とは</h1>\n",
    "機械学習をものすごく簡単に説明すると,大量のデータから何かをする方法を自動で作ることと言えます.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>かつての方法の例</h3>\n",
    "手元にwebサイトの顧客データが大量にあります.<br>\n",
    "この顧客データから,ユーザが興味があるであろう商品を自動でレコメンドしようという案がでました.<br>\n",
    "社内の人間（データサイエンティスト）たちがデータから顧客の傾向をまとめ,\n",
    "（家電カテゴリの商品を３点以上買ったら,〇〇の商品をレコメンド）のようなアルゴリズムを<br>\n",
    "人間(データサイエンティスト)が考えて組みます.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>機械学習を使うと</h3>\n",
    "手元にwebサイトの顧客データが大量にあります.<br>\n",
    "機械学習のモデルを組みます.<br>\n",
    "データを入れます,<br>\n",
    "アルゴリズムが出来上がります<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習の主な使いどころは（あくまで僕のイメージ）<strong>人間が考えてしてきた業務を自動化</strong>です.<br>\n",
    "<ul>\n",
    "    <li>領収書の入力の自動化</li>\n",
    "    <li>運転の自動化</li>\n",
    "    <li>画像のタグ付けの自動化</li>\n",
    "    <li>音声の文章おこしの自動化</li>\n",
    "    <li>ロボットの制御の自動化</li>\n",
    "</ul>\n",
    "などなど<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際のところ機械学習の理論やモデルを作ることは簡単です.<br>\n",
    "大変なのはデータ集めとそのデータを使える形式（たいていベクトル形式です.）に直すことです."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webなどの顧客データの場合,サイトを運営していればデータは自動で集まるし,<br>\n",
    "そのデータはおそらく下のような整列されたデータでしょう.<br>\n",
    "<table>\n",
    "    <tr><th>登録日</th><th>全購入数</th><th>購入品１のID</th><th>購入品１のカテゴリID</th><th>...</th></tr>\n",
    "    <tr><td>08/21</td><td>34</td><td>4123410</td><td>13489090</td><td>...</td></tr>\n",
    "    </table>\n",
    "このような場合であれば,良いのですが大抵そうはいきません."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>文章の場合</h4>\n",
    "文章の場合はデータを集めることは簡単です.（電子書籍,Webサイトのデータなど）<br>\n",
    "しかし,単語の区切りや文章の構成などをベクトル表現に直す方法をうまく考えなければなりません.<br>\n",
    "<h4>画像の場合</h4>\n",
    "画像はRGBの整列されたデータなので,ベクトル表現に直すのは簡単です.<br>\n",
    "しかし,目的（例えば車の運転,業務の作業工程）などは普通に生活していて手に入るものではないので,集めるためのアルゴリズムを<br>\n",
    "うまく考える必要があります(webのデータを取ってくる方法もありますが,だめなデータが多すぎて,たいていうまく行きません).<br>\n",
    "<h4>音楽の場合</h4>\n",
    "音楽は周波数のデジタルだし,世の中にたくさんデータがあるため,簡単にあつめられそうですが.<br>\n",
    "実際には普通の音楽のでデータ(MP3やWMVなど)は様々な楽器の音が一緒くたに入っているためあまり適しているとは言えません<br>\n",
    "学習に適しているデータ(MIDIなど)を改めて自分で作る必要があります<br>\n",
    "（生の音楽データで）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は生の文章をベクトルでどのように表現するかについて、説明する."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>テキストデータの処理</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字列データには大きく分けて４つの種類がある.<br>\n",
    "<ul>\n",
    "<li>カテゴリデータ</li>\n",
    "<li>カテゴリに分類できる自由な文字列</li>\n",
    "<li>構造化された文字列</li>\n",
    "<li>テキストデータ</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>テキストデータの例</h4>\n",
    "アンケートの入力で「犬についてどう思うか」、ドロップダウンメニューで[好き,嫌い]から選んでもらったデータ<br>\n",
    "データは決まった値しか取らず整列されている<br>\n",
    "<h4>カテゴリに分類できる自由な文字列の例</h4>\n",
    "アンケートの入力で「犬は好きですか,嫌いですか?」という質問を自由記述してもらったデータ<br>\n",
    "「好き」,「すごく好き」「嫌い」のようにカテゴリで分けやすいデータもあれば,「昔近所にいた犬に噛まれた.一生許さない.」のように自動でカテゴリに分類しづらいデータもある.<br>\n",
    "そのため「好き」「嫌い」「その他」のように分類するのが一般的<br>\n",
    "<h4>構造化された文字列の例</h4>\n",
    "住所,人名,日付など\n",
    "<h4>テキストデータの例</h4>\n",
    "ツイート,記事の文章,チャットログ,本のシナリオなど、最も生のデータ.<br>\n",
    "参考書が海外のものしかないため,生のデータがそのまま使われるが,日本語の場合は生のデータをそのまま使うことはできない.<br>\n",
    "英語の場合は<br>\n",
    "I like dog.Because dog is cute.<br>\n",
    "のように,単語の区切りは空欄で,文の区切りは.(ドット)で区別できる.しかし日本語の場合<br>\n",
    "私は犬が好きです。犬はかわいいから。<br>\n",
    "のように単語の区別がかんたんに行えない.<br>\n",
    "そのため日本語の場合は形態素解析(文章を意味ごとに分ける)が必要になる<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>BoWによるテキスト表現</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW(Bag of Words)とはテキストデータを特徴量で表現する最も単純な方法のひとつである.<br>\n",
    "テキストに現れたコーパスの単語をただ数えていくだけの方法である.<br>\n",
    "単語の順番や章立て,フォーマットなどテキストの持つ構造がほとんど失われる.<br>\n",
    "そのためBag Of Words(言葉の袋)とよばれる.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例:<br>\n",
    "コーパス：[犬,猫,魚,好き,嫌い]<br>\n",
    "テキスト：私は<strong>犬</strong>が<strong>好き</strong>である.<br>\n",
    "BoW表現：[1,0,0,1,0]<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>実際にやってみる</h3>\n",
    "今回はSMS Spanm collectionを使い,メールがスパムか否かを判別する."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>環境構築</h3>\n",
    "<a href=\"https://www.tensorflow.org/install/install_linux#InstallingVirtualenv\">tensorflow</a>のインストール\n",
    "<p> sudo apt-get install python3-pip python3-dev python-virtualenv</p>\n",
    "<p> pyvenv myvenv(自由な環境名)</p>\n",
    "<p>仮想環境のactivate</p>\n",
    "<p> source myvenv/bin/activate</p> \n",
    "これでpythonの仮想環境ができました.仮想環境の中でのみpythonコマンドでpython3を起動,pipコマンドでpip3が起動できます.\n",
    "<p>(myvenv) pip install --upgrade tensorflow </p>\n",
    "<p>(myvenv) pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp35-cp35m-linux_x86_64.whl</p>\n",
    "(僕の環境はpython3.5.3だったので上のコマンドでできますが,違うバージョンの場合は<br>\n",
    "https://www.tensorflow.org/install/install_linux#the_url_of_the_tensorflow_python_package\n",
    "からupgrade以下のパスの正しいものを選択して<br>\n",
    "ください.pythonのバージョンはpython -Vで確認できます}.)<br>\n",
    "jupyter notebookで実行すると理解しやすいです.<br>\n",
    "pip install jupyter[notebook]<br>\n",
    "jupyter notebookコマンドで起動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その他必要ライブラリのインストール<br>\n",
    "pip install requests<br>\n",
    "pip install matplotlib<br>\n",
    "pip install numpy<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests\n",
    "import io\n",
    "import string\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セッションを始めに定義しておく.<br>\n",
    "このセッションが最終的に計算グラフを追加していくインスタンスになる<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>学習に使用するデータのパスを定義</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データのパス:temp/temp_spam_data.csv\n"
     ]
    }
   ],
   "source": [
    "save_file_name = os.path.join('temp','temp_spam_data.csv')\n",
    "print('学習データのパス:{}'.format(save_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>学習データが存在しなければダウンロードする</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/temp_spam_data.csvからデータを読み込み,text_dataにlistで追加します.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('temp'):\n",
    "    print('\"temp\"ディレクトリが存在しません...作成します')\n",
    "    os.mkdir('temp')\n",
    "\n",
    "if os.path.isfile(save_file_name):\n",
    "    print('{}からデータを読み込み,text_dataにlistで追加します.'.format(save_file_name))\n",
    "    text_data=[]\n",
    "    with open(save_file_name,'r') as temp_output_file:\n",
    "        reader = csv.reader(temp_output_file)\n",
    "        for row in reader:\n",
    "            text_data.append(row)\n",
    "else:\n",
    "    zip_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "    print('{}が存在しません.{}から学習データをダウンロードします.'.format(save_file_name,zip_url))\n",
    "    r = requests.get(zip_url)\n",
    "    print('レスポンスが200なら成功:{}'.format(r))\n",
    "    print('ダウンロードしたzipの１文字目から30文字目')\n",
    "    print(r.content[0:30])\n",
    "    print('zipはbyteで保存されている')\n",
    "    print('')\n",
    "    z = ZipFile(io.BytesIO(r.content))\n",
    "    file = z.read('SMSSpamCollection')\n",
    "    print('zipファイルを位置文字ずつ読み込みZipFileのread関数で{}読める状態になる'.format(type(file)))\n",
    "    print('')\n",
    "    print('0文字目から30文字目は以下の用になっている.')\n",
    "    print(file[0:30])\n",
    "    print('スパム判定\\\\t文章文章文章....\\\\n')\n",
    "    print('というふうに保存されているためこれをひとつずつのスパム判別と文章に分け,text_data変数に格納.')\n",
    "    text_data = file.decode()\n",
    "    text_data = text_data.encode('ascii',errors='ignore')\n",
    "    text_data = text_data.decode().split('\\n')\n",
    "    text_data = [x.split('\\t') for x in text_data if len(x)>=1]\n",
    "    print('text_data変数の中身をファイルとして保存.')\n",
    "    with open(save_file_name,'w') as temp_output_file:\n",
    "        writer = csv.writer (temp_output_file)\n",
    "        writer.writerows(text_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとそのラベル（スパムか否か）を変数に格納\n",
    "texts = [x[1] for x in text_data]\n",
    "target = [x[0] for x in text_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データが文字列だと扱いづらいため,<br>\n",
    "1:spam<br>\n",
    "0:ham<br>\n",
    "と変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = [1 if x=='spam' else 0 for x in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>テキストの大文字と小文字の区別をなくす.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句読点などの記号の削除は!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~と整合をとって判断する\n"
     ]
    }
   ],
   "source": [
    "print('句読点などの記号の削除は{}と整合をとって判断する'.format(string.punctuation))\n",
    "texts = [\n",
    "    ''.join(c for c in x if c not in string.punctuation) for x in texts\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>次に数字を削除</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests=[\n",
    "    ''.join(c for c in x if c not in '0123456789') for x in texts\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>次に文の最大の長さを決定する(とりあえず０〜５０で)<br>\n",
    "英語の場合は空白で区切ることで単語数を判断できるが日本語の場合はこの処理の前に<br>\n",
    "形態素解析が必要になると思われる<br></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04dff3d470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_lengths = [len(x.split()) for x in texts]\n",
    "texts_lengths = [x for x in text_lengths if x < 50]\n",
    "plt.hist(text_lengths,bins=25)\n",
    "plt.title('ヒストグラム')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ヒストグラムから一つの文章ごとの単語のカットオフ値（最大値）を25にする<br>\n",
    "またデータベース全体で3回以上出現しない単語は,打ち間違いやそもそも判別に使うことに適していない単語であると推測できるため,<br>\n",
    "出現回数３回以上を条件とする.この処理をtensorflowのVocablaryProcessorを用いて行う</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_size = 25\n",
    "min_word=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "語彙数は2514\n"
     ]
    }
   ],
   "source": [
    "vocab_processor=learn.preprocessing.VocabularyProcessor(max_document_length=sentence_size,min_frequency=min_word)\n",
    "vocab_processor.fit_transform(tests)\n",
    "embedding_size = len(vocab_processor.vocabulary_)\n",
    "print('語彙数は{}'.format(embedding_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>次にデータを訓練データとテストデータに分ける</h3>\n",
    "train_indices,text_indicesでデータセットのどこから抜き出すかを定義しする."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_indicesの0から10番目\n",
      "[1459 4015 3061  738 2281 2706 1288 4171  876 2364]\n",
      "test_indicesの0から10番目\n",
      "[4096 2051    5 2054 4101 4102 4108   13 2063   16]\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.random.choice(len(texts),round(len(texts)*0.8),replace=False)\n",
    "test_indices = np.array(list(set(range(len(texts))) - set(train_indices)))\n",
    "print('train_indicesの0から10番目')\n",
    "print(train_indices[0:10])\n",
    "print('test_indicesの0から10番目')\n",
    "print(test_indices[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>定義したindicesからそれぞれtextとラベルを取得する</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = [x for ix , x in enumerate(texts) if ix in train_indices]\n",
    "texts_test = [x for ix , x in enumerate(texts) if ix in test_indices]\n",
    "target_train = [x for ix ,x in enumerate(target) if ix in train_indices]\n",
    "target_test =[x for ix,x in enumerate(target) if ix in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0]\n",
      "['FreeMsg Hey there darling its been 3 weeks now and no word back Id like some fun you up for it still Tb ok XxX std chgs to send 150 to rcv', 'Ive been searching for the right words to thank you for this breather I promise i wont take your help for granted and will fulfil my promise You have been wonderful and a blessing at all times', 'Oh kim watching here', 'Aft i finish my lunch then i go str down lor Ard 3 smth lor U finish ur lunch already', 'Ffffffffff Alright no way I can meet up with you sooner']\n"
     ]
    }
   ],
   "source": [
    "print(target_test[0:5])\n",
    "print(texts_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ある文に出現する単語をベクトルで表現するための行列を定義する.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_mat = tf.diag(tf.ones(shape=[embedding_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>モデルの定義</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable(変数)がモデルのグラフとなる初期値をランダムに与える.<br>\n",
    "入力データ(x_data)と正解データ(y_target)はplaceholder(定数)で定義する<br>\n",
    "入力データや正解データなどははじめに入れ物だけ定義して,実行時に値を順番に入れていく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.Variable(tf.random_normal(shape=[embedding_size,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "x_data = tf.placeholder(shape=[sentence_size],dtype=tf.int32)\n",
    "y_target=tf.placeholder(shape=[1,1],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2514, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(1, 1) dtype=float32_ref>\n",
      "Tensor(\"Placeholder:0\", shape=(25,), dtype=int32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print(b)\n",
    "print(x_data)\n",
    "print(y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>入力の与えられるAはembededing_sizeと同じサイズとなっている.<br>\n",
    "ある文章に存在する単語の出現状況がベクトルとなり入力されてくるということである<br>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed = tf.nn.embedding_lookup(params=identity_mat,ids=x_data)\n",
    "x_col_sums = tf.reduce_sum(input_tensor=x_embed,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(25, 2514), dtype=float32)\n",
      "Tensor(\"Sum:0\", shape=(2514,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x_embed)\n",
    "print(x_col_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>x_col_sums_2D : 文章中の単語を一つの行列であらわしたもの<br>\n",
    "model_output  : モデルの出力をあらわしたもの.<br></h3>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims:0\", shape=(1, 2514), dtype=float32)\n",
      "Tensor(\"Add:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_col_sums_2D = tf.expand_dims(x_col_sums, 0)\n",
    "model_output = tf.add(tf.matmul(x_col_sums_2D, A), b)\n",
    "print(x_col_sums_2D)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>loss:出力した値がラベルとどのくらい違うかを表す.学習時に使われる.\n",
    "prediction:実際の出力,spamかhamかを1か0で出力する.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target))\n",
    "prediction = tf.sigmoid(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimaizer（）とtrain_step(訓練回数),initializer(初期化関数)<br>\n",
    "パラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_opt = tf.train.GradientDescentOptimizer(0.001)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>sessの初期化</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>学習</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Over 4459 Sentences.\n",
      "Training Observation #10: Loss = 5.9777\n",
      "Training Observation #20: Loss = 12.5425\n",
      "Training Observation #30: Loss = 0.00100121\n",
      "Training Observation #40: Loss = 4.35148\n",
      "Training Observation #50: Loss = 8.97835\n",
      "Training Observation #60: Loss = 2.00104\n",
      "Training Observation #70: Loss = 0.312952\n",
      "Training Observation #80: Loss = 0.0121951\n",
      "Training Observation #90: Loss = 0.144773\n",
      "Training Observation #100: Loss = 1.10507\n",
      "Training Observation #110: Loss = 0.00137555\n",
      "Training Observation #120: Loss = 0.00709389\n",
      "Training Observation #130: Loss = 0.260443\n",
      "Training Observation #140: Loss = 0.900865\n",
      "Training Observation #150: Loss = 0.108904\n",
      "Training Observation #160: Loss = 0.00222816\n",
      "Training Observation #170: Loss = 0.0206201\n",
      "Training Observation #180: Loss = 1.95726\n",
      "Training Observation #190: Loss = 1.39074\n",
      "Training Observation #200: Loss = 0.000350692\n",
      "Training Observation #210: Loss = 0.702271\n",
      "Training Observation #220: Loss = 0.00143439\n",
      "Training Observation #230: Loss = 0.0305381\n",
      "Training Observation #240: Loss = 0.158696\n",
      "Training Observation #250: Loss = 2.0534\n",
      "Training Observation #260: Loss = 0.0947468\n",
      "Training Observation #270: Loss = 0.0075046\n",
      "Training Observation #280: Loss = 2.13723\n",
      "Training Observation #290: Loss = 0.00154807\n",
      "Training Observation #300: Loss = 1.78551\n",
      "Training Observation #310: Loss = 0.00360192\n",
      "Training Observation #320: Loss = 11.1947\n",
      "Training Observation #330: Loss = 0.00110551\n",
      "Training Observation #340: Loss = 0.00201573\n",
      "Training Observation #350: Loss = 0.0115462\n",
      "Training Observation #360: Loss = 0.000731981\n",
      "Training Observation #370: Loss = 0.9287\n",
      "Training Observation #380: Loss = 2.17596\n",
      "Training Observation #390: Loss = 0.290721\n",
      "Training Observation #400: Loss = 0.000263487\n",
      "Training Observation #410: Loss = 4.30338e-05\n",
      "Training Observation #420: Loss = 0.191901\n",
      "Training Observation #430: Loss = 2.6406\n",
      "Training Observation #440: Loss = 1.80258\n",
      "Training Observation #450: Loss = 1.09822\n",
      "Training Observation #460: Loss = 2.8033\n",
      "Training Observation #470: Loss = 0.000501574\n",
      "Training Observation #480: Loss = 8.69043\n",
      "Training Observation #490: Loss = 0.209385\n",
      "Training Observation #500: Loss = 0.00211781\n",
      "Training Observation #510: Loss = 0.00716248\n",
      "Training Observation #520: Loss = 2.16\n",
      "Training Observation #530: Loss = 0.124191\n",
      "Training Observation #540: Loss = 4.75542\n",
      "Training Observation #550: Loss = 0.467524\n",
      "Training Observation #560: Loss = 0.325971\n",
      "Training Observation #570: Loss = 2.74325\n",
      "Training Observation #580: Loss = 0.00171255\n",
      "Training Observation #590: Loss = 0.478715\n",
      "Training Observation #600: Loss = 7.29879e-06\n",
      "Training Observation #610: Loss = 0.0358838\n",
      "Training Observation #620: Loss = 7.83292\n",
      "Training Observation #630: Loss = 0.00065496\n",
      "Training Observation #640: Loss = 0.00764446\n",
      "Training Observation #650: Loss = 0.00280534\n",
      "Training Observation #660: Loss = 0.126974\n",
      "Training Observation #670: Loss = 0.0768394\n",
      "Training Observation #680: Loss = 0.00320153\n",
      "Training Observation #690: Loss = 0.0219722\n",
      "Training Observation #700: Loss = 2.75488\n",
      "Training Observation #710: Loss = 1.93212\n",
      "Training Observation #720: Loss = 0.0705658\n",
      "Training Observation #730: Loss = 0.00211866\n",
      "Training Observation #740: Loss = 0.00839924\n",
      "Training Observation #750: Loss = 0.00442955\n",
      "Training Observation #760: Loss = 0.0810956\n",
      "Training Observation #770: Loss = 0.000843284\n",
      "Training Observation #780: Loss = 0.0118188\n",
      "Training Observation #790: Loss = 0.0364657\n",
      "Training Observation #800: Loss = 7.15778e-05\n",
      "Training Observation #810: Loss = 0.0130655\n",
      "Training Observation #820: Loss = 1.76256\n",
      "Training Observation #830: Loss = 2.32441\n",
      "Training Observation #840: Loss = 0.764914\n",
      "Training Observation #850: Loss = 0.000739855\n",
      "Training Observation #860: Loss = 0.00499074\n",
      "Training Observation #870: Loss = 0.109296\n",
      "Training Observation #880: Loss = 2.90196\n",
      "Training Observation #890: Loss = 0.0168913\n",
      "Training Observation #900: Loss = 0.229002\n",
      "Training Observation #910: Loss = 0.00016465\n",
      "Training Observation #920: Loss = 7.73781e-06\n",
      "Training Observation #930: Loss = 0.000433746\n",
      "Training Observation #940: Loss = 8.14421e-05\n",
      "Training Observation #950: Loss = 0.00713555\n",
      "Training Observation #960: Loss = 0.0176118\n",
      "Training Observation #970: Loss = 0.0925628\n",
      "Training Observation #980: Loss = 0.0094614\n",
      "Training Observation #990: Loss = 4.43885e-07\n",
      "Training Observation #1000: Loss = 0.372119\n",
      "Training Observation #1010: Loss = 4.42838\n",
      "Training Observation #1020: Loss = 0.00116591\n",
      "Training Observation #1030: Loss = 3.65726e-06\n",
      "Training Observation #1040: Loss = 0.00694645\n",
      "Training Observation #1050: Loss = 2.20811e-05\n",
      "Training Observation #1060: Loss = 0.0141588\n",
      "Training Observation #1070: Loss = 0.0330841\n",
      "Training Observation #1080: Loss = 0.000438221\n",
      "Training Observation #1090: Loss = 0.0774716\n",
      "Training Observation #1100: Loss = 0.0946992\n",
      "Training Observation #1110: Loss = 5.42693\n",
      "Training Observation #1120: Loss = 1.74209\n",
      "Training Observation #1130: Loss = 0.000518022\n",
      "Training Observation #1140: Loss = 0.0815608\n",
      "Training Observation #1150: Loss = 0.0012915\n",
      "Training Observation #1160: Loss = 1.77839\n",
      "Training Observation #1170: Loss = 0.00548983\n",
      "Training Observation #1180: Loss = 0.0784718\n",
      "Training Observation #1190: Loss = 0.0159115\n",
      "Training Observation #1200: Loss = 0.000294585\n",
      "Training Observation #1210: Loss = 0.991194\n",
      "Training Observation #1220: Loss = 0.00218583\n",
      "Training Observation #1230: Loss = 0.000240636\n",
      "Training Observation #1240: Loss = 0.00108623\n",
      "Training Observation #1250: Loss = 0.00189957\n",
      "Training Observation #1260: Loss = 0.000685556\n",
      "Training Observation #1270: Loss = 0.00107244\n",
      "Training Observation #1280: Loss = 0.000247126\n",
      "Training Observation #1290: Loss = 0.288654\n",
      "Training Observation #1300: Loss = 0.0405153\n",
      "Training Observation #1310: Loss = 3.50395\n",
      "Training Observation #1320: Loss = 3.05137\n",
      "Training Observation #1330: Loss = 0.0028219\n",
      "Training Observation #1340: Loss = 0.168956\n",
      "Training Observation #1350: Loss = 0.0597198\n",
      "Training Observation #1360: Loss = 3.0201\n",
      "Training Observation #1370: Loss = 0.198428\n",
      "Training Observation #1380: Loss = 0.000938315\n",
      "Training Observation #1390: Loss = 0.000387845\n",
      "Training Observation #1400: Loss = 0.0431245\n",
      "Training Observation #1410: Loss = 1.34258e-05\n",
      "Training Observation #1420: Loss = 0.000842517\n",
      "Training Observation #1430: Loss = 0.00713893\n",
      "Training Observation #1440: Loss = 0.00265593\n",
      "Training Observation #1450: Loss = 0.0374754\n",
      "Training Observation #1460: Loss = 4.34615\n",
      "Training Observation #1470: Loss = 0.00585659\n",
      "Training Observation #1480: Loss = 0.00872908\n",
      "Training Observation #1490: Loss = 2.4388\n",
      "Training Observation #1500: Loss = 0.00150588\n",
      "Training Observation #1510: Loss = 1.12435\n",
      "Training Observation #1520: Loss = 0.000662503\n",
      "Training Observation #1530: Loss = 0.000140582\n",
      "Training Observation #1540: Loss = 0.0328778\n",
      "Training Observation #1550: Loss = 0.000139462\n",
      "Training Observation #1560: Loss = 0.000163556\n",
      "Training Observation #1570: Loss = 0.000305932\n",
      "Training Observation #1580: Loss = 0.000429682\n",
      "Training Observation #1590: Loss = 0.141101\n",
      "Training Observation #1600: Loss = 0.0975789\n",
      "Training Observation #1610: Loss = 0.0040774\n",
      "Training Observation #1620: Loss = 0.000370024\n",
      "Training Observation #1630: Loss = 0.000151716\n",
      "Training Observation #1640: Loss = 0.000141935\n",
      "Training Observation #1650: Loss = 0.0606065\n",
      "Training Observation #1660: Loss = 0.00121873\n",
      "Training Observation #1670: Loss = 0.00705417\n",
      "Training Observation #1680: Loss = 0.132311\n",
      "Training Observation #1690: Loss = 0.00470823\n",
      "Training Observation #1700: Loss = 0.000215912\n",
      "Training Observation #1710: Loss = 0.000139693\n",
      "Training Observation #1720: Loss = 0.0221915\n",
      "Training Observation #1730: Loss = 0.00309031\n",
      "Training Observation #1740: Loss = 0.00400295\n",
      "Training Observation #1750: Loss = 0.000209703\n",
      "Training Observation #1760: Loss = 0.531069\n",
      "Training Observation #1770: Loss = 0.00598177\n",
      "Training Observation #1780: Loss = 0.831612\n",
      "Training Observation #1790: Loss = 0.0288654\n",
      "Training Observation #1800: Loss = 0.000129043\n",
      "Training Observation #1810: Loss = 0.247569\n",
      "Training Observation #1820: Loss = 0.000896374\n",
      "Training Observation #1830: Loss = 0.00601606\n",
      "Training Observation #1840: Loss = 0.295488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Observation #1850: Loss = 0.00287776\n",
      "Training Observation #1860: Loss = 3.7586\n",
      "Training Observation #1870: Loss = 0.000165167\n",
      "Training Observation #1880: Loss = 4.29964\n",
      "Training Observation #1890: Loss = 0.0248004\n",
      "Training Observation #1900: Loss = 1.45243\n",
      "Training Observation #1910: Loss = 0.0101664\n",
      "Training Observation #1920: Loss = 0.00480969\n",
      "Training Observation #1930: Loss = 0.0138292\n",
      "Training Observation #1940: Loss = 0.000156809\n",
      "Training Observation #1950: Loss = 0.0059588\n",
      "Training Observation #1960: Loss = 0.00749456\n",
      "Training Observation #1970: Loss = 1.69679e-06\n",
      "Training Observation #1980: Loss = 0.000382882\n",
      "Training Observation #1990: Loss = 0.312279\n",
      "Training Observation #2000: Loss = 0.0052276\n",
      "Training Observation #2010: Loss = 0.00134426\n",
      "Training Observation #2020: Loss = 0.0197222\n",
      "Training Observation #2030: Loss = 7.59182e-05\n",
      "Training Observation #2040: Loss = 0.00914761\n",
      "Training Observation #2050: Loss = 0.000569505\n",
      "Training Observation #2060: Loss = 0.0167637\n",
      "Training Observation #2070: Loss = 2.64135e-05\n",
      "Training Observation #2080: Loss = 0.000976367\n",
      "Training Observation #2090: Loss = 0.00024374\n",
      "Training Observation #2100: Loss = 0.0294391\n",
      "Training Observation #2110: Loss = 9.39058e-05\n",
      "Training Observation #2120: Loss = 0.000536459\n",
      "Training Observation #2130: Loss = 8.4543\n",
      "Training Observation #2140: Loss = 1.05599e-05\n",
      "Training Observation #2150: Loss = 0.000555532\n",
      "Training Observation #2160: Loss = 0.00268183\n",
      "Training Observation #2170: Loss = 0.00111097\n",
      "Training Observation #2180: Loss = 0.0249768\n",
      "Training Observation #2190: Loss = 3.71294\n",
      "Training Observation #2200: Loss = 2.06052e-05\n",
      "Training Observation #2210: Loss = 9.3561e-06\n",
      "Training Observation #2220: Loss = 0.000262242\n",
      "Training Observation #2230: Loss = 0.600169\n",
      "Training Observation #2240: Loss = 5.19171\n",
      "Training Observation #2250: Loss = 0.592937\n",
      "Training Observation #2260: Loss = 0.200576\n",
      "Training Observation #2270: Loss = 0.0274359\n",
      "Training Observation #2280: Loss = 0.0187267\n",
      "Training Observation #2290: Loss = 0.000498209\n",
      "Training Observation #2300: Loss = 0.0933174\n",
      "Training Observation #2310: Loss = 0.000170206\n",
      "Training Observation #2320: Loss = 0.00606059\n",
      "Training Observation #2330: Loss = 0.00112038\n",
      "Training Observation #2340: Loss = 0.0244927\n",
      "Training Observation #2350: Loss = 0.000579654\n",
      "Training Observation #2360: Loss = 0.0146198\n",
      "Training Observation #2370: Loss = 6.10021\n",
      "Training Observation #2380: Loss = 5.19765\n",
      "Training Observation #2390: Loss = 8.31077e-05\n",
      "Training Observation #2400: Loss = 0.00816975\n",
      "Training Observation #2410: Loss = 5.6275\n",
      "Training Observation #2420: Loss = 3.53913\n",
      "Training Observation #2430: Loss = 0.00247835\n",
      "Training Observation #2440: Loss = 0.0947766\n",
      "Training Observation #2450: Loss = 0.0808199\n",
      "Training Observation #2460: Loss = 0.0882662\n",
      "Training Observation #2470: Loss = 0.000410597\n",
      "Training Observation #2480: Loss = 0.115604\n",
      "Training Observation #2490: Loss = 5.6198e-05\n",
      "Training Observation #2500: Loss = 0.0345716\n",
      "Training Observation #2510: Loss = 4.36845\n",
      "Training Observation #2520: Loss = 5.89852e-05\n",
      "Training Observation #2530: Loss = 0.00172704\n",
      "Training Observation #2540: Loss = 1.44175e-05\n",
      "Training Observation #2550: Loss = 2.18617e-05\n",
      "Training Observation #2560: Loss = 0.00204405\n",
      "Training Observation #2570: Loss = 0.00111129\n",
      "Training Observation #2580: Loss = 0.00103062\n",
      "Training Observation #2590: Loss = 0.115533\n",
      "Training Observation #2600: Loss = 4.99163e-05\n",
      "Training Observation #2610: Loss = 0.693793\n",
      "Training Observation #2620: Loss = 8.84494e-06\n",
      "Training Observation #2630: Loss = 0.0227645\n",
      "Training Observation #2640: Loss = 0.227634\n",
      "Training Observation #2650: Loss = 0.000923829\n",
      "Training Observation #2660: Loss = 5.56162e-05\n",
      "Training Observation #2670: Loss = 4.74446e-06\n",
      "Training Observation #2680: Loss = 0.00967041\n",
      "Training Observation #2690: Loss = 0.00896251\n",
      "Training Observation #2700: Loss = 4.36328\n",
      "Training Observation #2710: Loss = 3.51134\n",
      "Training Observation #2720: Loss = 0.0294646\n",
      "Training Observation #2730: Loss = 0.871449\n",
      "Training Observation #2740: Loss = 0.000130498\n",
      "Training Observation #2750: Loss = 0.0248613\n",
      "Training Observation #2760: Loss = 0.00207855\n",
      "Training Observation #2770: Loss = 0.0798783\n",
      "Training Observation #2780: Loss = 0.000501314\n",
      "Training Observation #2790: Loss = 0.000109057\n",
      "Training Observation #2800: Loss = 0.0192884\n",
      "Training Observation #2810: Loss = 0.766296\n",
      "Training Observation #2820: Loss = 0.000579472\n",
      "Training Observation #2830: Loss = 0.000302328\n",
      "Training Observation #2840: Loss = 0.0276042\n",
      "Training Observation #2850: Loss = 0.152217\n",
      "Training Observation #2860: Loss = 0.000134227\n",
      "Training Observation #2870: Loss = 4.2084e-05\n",
      "Training Observation #2880: Loss = 0.00179404\n",
      "Training Observation #2890: Loss = 0.000749622\n",
      "Training Observation #2900: Loss = 0.0855239\n",
      "Training Observation #2910: Loss = 0.0111908\n",
      "Training Observation #2920: Loss = 0.0014424\n",
      "Training Observation #2930: Loss = 0.000470257\n",
      "Training Observation #2940: Loss = 0.000426182\n",
      "Training Observation #2950: Loss = 0.0379027\n",
      "Training Observation #2960: Loss = 0.00526681\n",
      "Training Observation #2970: Loss = 0.00160116\n",
      "Training Observation #2980: Loss = 0.093755\n",
      "Training Observation #2990: Loss = 0.000163462\n",
      "Training Observation #3000: Loss = 0.00313902\n",
      "Training Observation #3010: Loss = 0.000265295\n",
      "Training Observation #3020: Loss = 0.0337102\n",
      "Training Observation #3030: Loss = 0.000564097\n",
      "Training Observation #3040: Loss = 6.03935\n",
      "Training Observation #3050: Loss = 0.000527586\n",
      "Training Observation #3060: Loss = 0.00251994\n",
      "Training Observation #3070: Loss = 0.000557492\n",
      "Training Observation #3080: Loss = 0.289238\n",
      "Training Observation #3090: Loss = 0.00692648\n",
      "Training Observation #3100: Loss = 3.1086\n",
      "Training Observation #3110: Loss = 0.0195545\n",
      "Training Observation #3120: Loss = 0.0100181\n",
      "Training Observation #3130: Loss = 0.000101591\n",
      "Training Observation #3140: Loss = 0.0015276\n",
      "Training Observation #3150: Loss = 8.80461e-05\n",
      "Training Observation #3160: Loss = 0.0108342\n",
      "Training Observation #3170: Loss = 0.809595\n",
      "Training Observation #3180: Loss = 0.00114038\n",
      "Training Observation #3190: Loss = 0.621461\n",
      "Training Observation #3200: Loss = 0.00308958\n",
      "Training Observation #3210: Loss = 0.131321\n",
      "Training Observation #3220: Loss = 0.000472852\n",
      "Training Observation #3230: Loss = 0.344525\n",
      "Training Observation #3240: Loss = 2.74791\n",
      "Training Observation #3250: Loss = 0.90349\n",
      "Training Observation #3260: Loss = 6.90703\n",
      "Training Observation #3270: Loss = 0.177276\n",
      "Training Observation #3280: Loss = 1.49922\n",
      "Training Observation #3290: Loss = 5.58925\n",
      "Training Observation #3300: Loss = 0.0699902\n",
      "Training Observation #3310: Loss = 0.000889758\n",
      "Training Observation #3320: Loss = 0.00829472\n",
      "Training Observation #3330: Loss = 0.00763735\n",
      "Training Observation #3340: Loss = 0.011612\n",
      "Training Observation #3350: Loss = 0.000146532\n",
      "Training Observation #3360: Loss = 1.45305e-05\n",
      "Training Observation #3370: Loss = 6.56219e-05\n",
      "Training Observation #3380: Loss = 0.363196\n",
      "Training Observation #3390: Loss = 7.67472\n",
      "Training Observation #3400: Loss = 0.000429825\n",
      "Training Observation #3410: Loss = 0.000815514\n",
      "Training Observation #3420: Loss = 0.00773349\n",
      "Training Observation #3430: Loss = 0.000101673\n",
      "Training Observation #3440: Loss = 0.10069\n",
      "Training Observation #3450: Loss = 0.0101404\n",
      "Training Observation #3460: Loss = 0.000275072\n",
      "Training Observation #3470: Loss = 0.000133639\n",
      "Training Observation #3480: Loss = 0.0457164\n",
      "Training Observation #3490: Loss = 0.000550691\n",
      "Training Observation #3500: Loss = 0.173633\n",
      "Training Observation #3510: Loss = 0.000399094\n",
      "Training Observation #3520: Loss = 0.0042528\n",
      "Training Observation #3530: Loss = 0.0157592\n",
      "Training Observation #3540: Loss = 7.86728e-05\n",
      "Training Observation #3550: Loss = 3.72399e-05\n",
      "Training Observation #3560: Loss = 0.879341\n",
      "Training Observation #3570: Loss = 0.0106209\n",
      "Training Observation #3580: Loss = 8.60491\n",
      "Training Observation #3590: Loss = 6.31001e-05\n",
      "Training Observation #3600: Loss = 1.62081\n",
      "Training Observation #3610: Loss = 4.70862e-05\n",
      "Training Observation #3620: Loss = 0.00964314\n",
      "Training Observation #3630: Loss = 0.000746633\n",
      "Training Observation #3640: Loss = 3.45162e-05\n",
      "Training Observation #3650: Loss = 0.00055527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Observation #3660: Loss = 0.00916088\n",
      "Training Observation #3670: Loss = 0.00274183\n",
      "Training Observation #3680: Loss = 0.00034307\n",
      "Training Observation #3690: Loss = 1.68132e-05\n",
      "Training Observation #3700: Loss = 0.000700482\n",
      "Training Observation #3710: Loss = 8.90829e-05\n",
      "Training Observation #3720: Loss = 0.00787085\n",
      "Training Observation #3730: Loss = 0.218233\n",
      "Training Observation #3740: Loss = 0.0055334\n",
      "Training Observation #3750: Loss = 0.275006\n",
      "Training Observation #3760: Loss = 0.0740217\n",
      "Training Observation #3770: Loss = 0.104154\n",
      "Training Observation #3780: Loss = 0.00277074\n",
      "Training Observation #3790: Loss = 0.0101942\n",
      "Training Observation #3800: Loss = 0.0459137\n",
      "Training Observation #3810: Loss = 7.13746\n",
      "Training Observation #3820: Loss = 0.00134437\n",
      "Training Observation #3830: Loss = 0.414546\n",
      "Training Observation #3840: Loss = 0.000343003\n",
      "Training Observation #3850: Loss = 4.02975\n",
      "Training Observation #3860: Loss = 0.00022191\n",
      "Training Observation #3870: Loss = 0.000850995\n",
      "Training Observation #3880: Loss = 6.39401e-06\n",
      "Training Observation #3890: Loss = 0.00209133\n",
      "Training Observation #3900: Loss = 0.000163722\n",
      "Training Observation #3910: Loss = 7.85258e-05\n",
      "Training Observation #3920: Loss = 0.474625\n",
      "Training Observation #3930: Loss = 0.0875995\n",
      "Training Observation #3940: Loss = 0.000100511\n",
      "Training Observation #3950: Loss = 0.000279371\n",
      "Training Observation #3960: Loss = 2.14371\n",
      "Training Observation #3970: Loss = 6.98095\n",
      "Training Observation #3980: Loss = 3.64413\n",
      "Training Observation #3990: Loss = 0.0540305\n",
      "Training Observation #4000: Loss = 0.00685861\n",
      "Training Observation #4010: Loss = 0.000378066\n",
      "Training Observation #4020: Loss = 0.152128\n",
      "Training Observation #4030: Loss = 4.13474e-05\n",
      "Training Observation #4040: Loss = 4.0517e-05\n",
      "Training Observation #4050: Loss = 0.00225565\n",
      "Training Observation #4060: Loss = 0.433463\n",
      "Training Observation #4070: Loss = 0.0183065\n",
      "Training Observation #4080: Loss = 3.75679e-05\n",
      "Training Observation #4090: Loss = 0.505041\n",
      "Training Observation #4100: Loss = 0.459378\n",
      "Training Observation #4110: Loss = 3.50146\n",
      "Training Observation #4120: Loss = 9.5998\n",
      "Training Observation #4130: Loss = 1.76761e-06\n",
      "Training Observation #4140: Loss = 0.0112575\n",
      "Training Observation #4150: Loss = 4.0567\n",
      "Training Observation #4160: Loss = 2.73119e-05\n",
      "Training Observation #4170: Loss = 0.0719471\n",
      "Training Observation #4180: Loss = 0.0234928\n",
      "Training Observation #4190: Loss = 0.00991089\n",
      "Training Observation #4200: Loss = 0.00241637\n",
      "Training Observation #4210: Loss = 0.0865643\n",
      "Training Observation #4220: Loss = 0.00439771\n",
      "Training Observation #4230: Loss = 0.0135674\n",
      "Training Observation #4240: Loss = 0.00473387\n",
      "Training Observation #4250: Loss = 0.0275919\n",
      "Training Observation #4260: Loss = 0.104189\n",
      "Training Observation #4270: Loss = 0.00577478\n",
      "Training Observation #4280: Loss = 0.00238012\n",
      "Training Observation #4290: Loss = 0.454726\n",
      "Training Observation #4300: Loss = 0.00517953\n",
      "Training Observation #4310: Loss = 0.842227\n",
      "Training Observation #4320: Loss = 0.016915\n",
      "Training Observation #4330: Loss = 0.0125222\n",
      "Training Observation #4340: Loss = 0.0648489\n",
      "Training Observation #4350: Loss = 0.00063342\n",
      "Training Observation #4360: Loss = 0.00416467\n",
      "Training Observation #4370: Loss = 0.000362438\n",
      "Training Observation #4380: Loss = 7.37481\n",
      "Training Observation #4390: Loss = 0.0298738\n",
      "Training Observation #4400: Loss = 0.00242047\n",
      "Training Observation #4410: Loss = 0.473032\n",
      "Training Observation #4420: Loss = 0.020237\n",
      "Training Observation #4430: Loss = 0.0395576\n",
      "Training Observation #4440: Loss = 0.00943313\n",
      "Training Observation #4450: Loss = 1.46907\n",
      "Getting Test Set Accuracy For 1115 Sentences.\n"
     ]
    }
   ],
   "source": [
    "print('Starting Training Over {} Sentences.'.format(len(texts_train)))\n",
    "loss_vec = []\n",
    "train_acc_all = []\n",
    "train_acc_avg = []\n",
    "# \n",
    "for ix, t in enumerate(vocab_processor.fit_transform(texts_train)):\n",
    "    #正解データを定義\n",
    "    y_data = [[target_train[ix]]]\n",
    "    #sess.runで実行となる.\n",
    "    #run()の引数が実行されるノードである.\n",
    "    #train_stepはlossを引数にもち,lossはmodel_putputとy_targetsを...\n",
    "    #というふうにモデルのすべてが実行されるような形になる.\n",
    "    #feed_dictはからのplaceholderで定義した入れ物に入れる値\n",
    "    #x_dataが入力データでy_dataが正解データ\n",
    "    # _, temp_loss=sess.run(train_step,loss,feed_dict={x_data: t, y_target: y_data})としても良い....はず\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x_data: t, y_target: y_data})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: t, y_target: y_data})\n",
    "    #loss_vecにlossを記録しておく.\n",
    "    #これは記録しているだけなのであしからず\n",
    "    #tensorboardというものを使うと便利です.(今回は紹介せず)\n",
    "    loss_vec.append(temp_loss)\n",
    "    #10回ごとに何回学習させたかをprint\n",
    "    if (ix+1)%10==0:\n",
    "        print('Training Observation #' + str(ix+1) + ': Loss = ' + str(temp_loss))\n",
    "    #predictionを実行して,これも記録用\n",
    "    [[temp_pred]] = sess.run(prediction, feed_dict={x_data:t, y_target:y_data})\n",
    "    \n",
    "    train_acc_temp = target_train[ix]==np.round(temp_pred)\n",
    "    train_acc_all.append(train_acc_temp)\n",
    "    if len(train_acc_all) >= 50:\n",
    "        train_acc_avg.append(np.mean(train_acc_all[-50:]))\n",
    "\n",
    "print('Getting Test Set Accuracy For {} Sentences.'.format(len(texts_test)))\n",
    "test_acc_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>学習させたモデルでテスト</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Observation #50\n",
      "Test Observation #100\n",
      "Test Observation #150\n",
      "Test Observation #200\n",
      "Test Observation #250\n",
      "Test Observation #300\n",
      "Test Observation #350\n",
      "Test Observation #400\n",
      "Test Observation #450\n",
      "Test Observation #500\n",
      "Test Observation #550\n",
      "Test Observation #600\n",
      "Test Observation #650\n",
      "Test Observation #700\n",
      "Test Observation #750\n",
      "Test Observation #800\n",
      "Test Observation #850\n",
      "Test Observation #900\n",
      "Test Observation #950\n",
      "Test Observation #1000\n",
      "Test Observation #1050\n",
      "Test Observation #1100\n",
      "\n",
      "Overall Test Accuracy: 0.7784753363228699\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXm4VlX1+D+Ley8zCiiRgAqkZpiIimgOaKUlaloOhSMN\nZlpWmlPOpkZaOVDqt/yZliYooikqzhJqpYA45YDiCIKGIPNw7+Wu3x/n3Yf9nvec9z3vdMf1eZ77\n3Pecs88+6+xzzl5777X22qKqGIZhGAZAp5YWwDAMw2g9mFIwDMMwQkwpGIZhGCGmFAzDMIwQUwqG\nYRhGiCkFwzAMI8SUQgdHRIaKyKpKpzWM1oqIjBORh1pajtaKKYUKIyL/FJFPRaRLFfLeSkRWeX8q\nIqu97X2KzVNV31HVnpVOWyoicnnmvnatUv47iMgDIrJcRFaKyBMisns1rpVw/WdEZF3meS0WkSki\n8tkK5PndPMdrY96VP3nHO4nI70VkqYgsEZHfFLjepiJyrYi8n8nzAxG5S0R2K+c+qoGIbCMiWZOx\nVPVvqjqmpWRq7ZhSqCAiMhjYB1Dg0Ernr6ofqGpP95fZvZO37+kYmWoqLUe1EBEBjgeWAidUIf9t\ngX8Bc4DBwEDgfuAJERlVhesllf3Jmee3PdAP+H2lr53ADt67crK3/xTgIOCLwE7A4SJyYlwGItIV\nmE4g+0HAJsAXgMlAs1e0ben9bjOoqv1V6A+4iKDSuRp4wNu/O/ARUOPt+xbwcuZ3N+BvwKfA68DZ\nwIIU11Ngm8i+vwPXAw8Dq4H9CBTUi8AK4APgQi/9NsFrEG4/A/wK+DewMpNP32LTZo5/L3O9T4Dz\ngAXAfnnu5ysZmY8HFgN1keM/At7IXOu/BAoRYGvg3sw5nwATEvKfBEyN2f//gCczvx8jqLT94/8F\nDs38HgY8TqC43gCOyFf2Mdd6Bviut/1z4MXM73zPqTswEVgCLANmApsDVwIbgHXAKuDamGvWZt6V\nwQnlMhP4fqScn0lIezLwIdCtwLtZqJz+ADyUeZb/AYYUcW4x7/fCzL2vyvztBpwI/NNLszcwG1ie\nKYvdU34Psc+kpeqfSv21uADt6Q+YB/wY2BVoAPp7x94GDvC27wJ+mfl9BTAD6AMMAl6mPKXwKfAl\ngp5gF4LKdofM9k4EFechmfRxFf1bwLaZl/5p4PIS0u6Y+Yj2zMhwDdBIfqXwt8xH1iXzkR3mHTsa\nmJ8pWwG2A7YkqPD+S9Da7kGgYPdKyP8T4PiY/QdknlcX4PvADO/YTpmPvjPQk6BCPCFz3V0zxz6f\nVPYx1wqVAkEvYQZwS2Y733P6CYHi6wbUACOBntE8E+7bKYWFBI2TKcDW3vHVwK7e9h7Apwl5TQFu\nKvBepimnTzL3UAfcCfy9iHNLfr8z+0KlQKBYl2fer1qCBskSoE+KdzzxmbTlPxs+qhAisjdBi3Wy\nqj5PoASO8ZJMInjxEJFeBF3vSZlj3wbGq+qnqrqAoBVVDv9Q1f+oapOqrlfVJ1X11cz2S8AdwL55\nzv+Lqr6lqmsIlNeIEtIeBdyrqv9W1fXABfkEFpGewBHAxEz6u8keQjoRuEJVn9eAN1V1PkHlsDlw\njqquVtW1qvqvmPwF2AxYFHP5RQQVQu/MdXcTkUGZY8cAd6tqPXAY8Kaq3qqqjZnnfC9wpJdXVtkn\n3O4NIrKMoHX7AXAmQIHn1JC5z21UdYOqzlbVtEb/DcBogiGzLxD0qKaKSE2mXLoTVIyO5UCvhLw2\nJ1AsAIjISBFZJiIrROTVzO405TQlcw8NwO1sfG+KLuMS3m+fbwCvquqkzPVuA94BDvbSJL3j5TyT\nVosphcoxDnhUVT/JbE/M7MPbPjxjgD4cmKOq72eODSBoBTv836WQdb6IfCljAF8sIssJKtjN85z/\nkfd7DUHrrdi0WfekqqsJWnhJHEEwBPJIZvt24BAR6ZvZ3pJA0UbZEnhPVTfkyTtoKgYtwC1iDm9B\nUHEuU9XlBEME38lUmGMzskCg9PfKVILLMhX7dyJ5pnl2P1bV3qo6UFWPV9UlUPA5/ZVgSGWyiHwo\nIleISG2Ka5FRok+rar2qfgr8jKCntV2mXNYQ2AYcmxD08uLIKsNMRdiboGHjnCvSlFPSe1N0GZfw\nfvsMAN6P7HufwN5USNa/UuIzac2YUqgAItKN4KPYV0Q+EpGPgNOBnURkJwBVfY3gZRtD0Pqc6GWx\niGDYyLFlmSJFQ9/eQdAC3lJVNwVuIhiCqSZZ9yQiPQiGx5IYR1AZzc+U3ySCIZujM8fnA5+LOW8+\nsHVKg+PjBD2YKN8mGEN3LXvXq9ub4Bt5yrvWE5kK3f31VNVTvbzKCTuc+JwyFfolqvqFjFzfAo4t\n8Zqa+XPvwKsEwy6OnTL74ngCOFBEuufJP005lXNuMe93obJZSKCIfLYiGMLKS4Fn0mYxpVAZvknQ\n0hxG0LUcQdBNf5rsIZCJBIbF0QTdUMdk4FwR6SMiA4E0H08x9AKWquo6EdmDoPVbbe4Cvikie4hI\nZ+DSpIQisjWBwXAMG8tvJ+AqNpbfTcDZIrKzBGwrIlsSGCmXAONFpLuIdBORvRIudQmB4r40U9a9\nROQ0AiX9Sy/d/QRjyBcBd2Ra0wBTgR1E5BgRqcv8jRKRzxdXNIkkPicR+YqIfFFEOhEYVBuApszh\nj4GhSZmKyI4islNmuKgXgX3nfeDNTJJbgTNEZEBm2Ox0glZwHLcQjNnfI4F7b02mUTTSS1NOOZVy\nbr73+3+AikhS+TyQud53JHDdPYbADvFgIUELPJM2iymFyjCOwFj4gap+5P6A64BjvS7lJIKxzie9\nYSYIKswFwLsErdkpQNJ4dCmcAvxGRFYSeAFNrmDesajqywSVy10ErbElmb+4+zoemKWqT0TKbwKw\nq4hsr6qTCDxt7iT4AO8hMAY2AocQKOH5BGP0R8ZcA1V9g8BleCRBpbiIYAz7AFV91ku3jmAce3+8\nHl1maOnrwHGZcz8CfsPGYZNyyfecBhDc8wqCVvzjnmzXAkdnhluujsm3fyavFQRDcIMIDLGNmeM3\nEAzbvUrg5HAf8Jc4AVV1LcE7PJfAe2gFgYfQTmQq43LKqcRzE8tNVVdmzn8uUz6+8kJVFxN4L51D\n8H6eTlA2+YY6HfmeSZtFNjaCjNaCiJwCjFXVtMayVo+IbELgUbR1xkBsGEYrxHoKrQAR2UJE9pJg\nZunngTOAf7S0XOUiIodmhnR6EgwFzTGFYBitG1MKrYPOwJ8JPD6eJOi+39CiElWGbxEMHS0gcIc8\nOm9qwzBaHBs+MgzDMEKsp2AYhmGEtLmJFptvvrkOHjy4pcUwDMNoUzz//POfqGq/QunanFIYPHgw\ns2fPbmkxDMMw2hQiEp25HYsNHxmGYRghphQMwzCMEFMKhmEYRogpBcMwDCPElIJhGIYRYkrBMAzD\nCDGlYBiGYYSYUugAvPLKK1x33XW01ZAmt99+O6+88kpF87ztttt49dWkdWQqw5tvvsmTTz5Z1WsU\ny+LFi/nDH/5AQ0MDzz33HBMnZkd6vvXWW3nmmWdaSDqjNdDmYh+NHDlSbfJacQwbNozXX3+dt99+\nm6FDE9diaZU0NjZSV1fHkCFDeOeddyqSZ319PV26dGG77bZj7ty5FckzjmA1T1qVMj7ttNOYMGEC\n06ZN48gjj2TNmjU0NTUhImG5iAhNTW1+rRgjgog8r6ojC6WznkIH4PXXXwdg/fpKrtvTPNTX1wPw\n7rvvVizPdevWAUFLvqOxYMECAFavXs2aNWsAaGhoADaWdWtSYkbzY0qhA+E+/rZENRSZq/w6Iq73\n4vcEXHm0xffDqDymFDoQbfGjr0YF3hZ7TJWiU6fgk/d7A6482uL7YVQeUwptGFUtauy3LX70Ld1T\nqMRQSjl5FDq3mHfAz6uxsTH8XV9fj6p2aGXZUrTGoTpTCm2Yk08+mU022YTly5cnpnHDBdA2lcLz\nzz9f8Tw//vjj1Gl32mknLrzwwpz9l112WVbZ5mP16tWpr+fT0NBA//79GT9+fGKaTp06UVNTk0qW\nTp06MXlysKb9cccdF+4fMGAAO+ywA1tttVW4b8OGDSXJXAxr1qxBRLjpppuqfq3WyJlnnkmnTp24\n+eabW1qUbFS1Tf3tuuuuagQACuibb75ZMA2gTzzxRDNKVxluueUWBbR3794Vy3P69OlhmRQiKZ3b\n39TUVPDc+fPnlyTn0qVLC8rpP99C+GkL/a1YsaIkmYvhnXfeUUAHDx5c9Wu1RlxZb7vtts11vdma\noo61nkI7IG0PoC32FNxQT+/evSueZ5cuXcrOK02ZlmoXacnn1RzGeM0Mnbj/HRVn52ktVFUaETlQ\nROaKyDwR+WXM8a1F5AkReVlE/ikig6opT3vFHx/OR1tWCmmHaorJs6amJm+6NJVVmsqz1LH6tM+1\nGnRkD63mprUpxaopBRGpAa4HxgDDgKNFZFgk2e+BW1V1OHAp8JtqydOeac89BVehVrI1lTbPNOPq\naSr8UpVCoecVrUwqOeGsOYzOTv5KKvy2SGv7LqvZUxgFzFPVd1S1HrgDOCySZhjg4gBMjzlupCDp\npVq5cmXW9vnnn98c4gCwaNEifve737F27dqy8rnllluAyk1eW758ORdffDFQWCmk+Vg/+eSTgmmW\nLl2aTrgMqsp1111XcHLdOeeck7XtJuXFUazCWLJkSVHpS6G5KsPHH3+c1157DQhCpgwbNoyzzjqr\npLxUlSFDhvDnP/85a//atWu56aabElv9r732WpZB/f777w9/+z3CP/7xjxx++OEt23tIY3go5Q84\nErjJ2z4euC6SZiLw88zvwwkML5vF5HUSMBuYvdVWW1XS9tJm8Y2QTz31VGya+++/P8eAuGzZsmaR\n78c//rECet9995Wcx6pVq0K5e/XqVRG5Jk+eHOY5dOjQvGmXL19e0NB85513Jp7v0tx9991Fyfj+\n++8roIMGDUq8fkNDQ86znTNnTmKe69atC9P16NGjoKF5ypQpRclcCi+//HKzGJr9MvTvMZ+TQBJ3\n3XVX7DM57bTTFNCpU6fGnrfDDjtkGfB9OQ466KAcWd99992iZSsEbcTQfCawr4i8AOwLfAjk9NlV\n9UZVHamqI/v169fcMrZK/FZhUovLpXn55ZfDfc01Tu3cPssZm/bvsdD4f1pcz2X48OF07949b9o0\nLdk0LfBiW+lORheSIg5/aOvcc88F8svrnvuVV17JqlWrwgrg9NNPB+CMM85AVcPAg80R+8jJq83U\nKo5epxS326SeoXvfV6xYEXvcBV+MG5YbNiw6qp6/11dtaquY94fAlt72oMy+EFVdSNBDQER6Akeo\n6rIqytRu8CvbpIrevYC+l01rG7/Mh5O/Z8+eFZPblVuPHj349NNP86ZNKle/ckmjZIsdn4+mjxtz\n9ys093zTKIW6urqs/bW1tVl5uOPN8Z40tyE92kCpr68P77/UPBxpgx/GnR9XDi1p6K9mT2EWsK2I\nDBGRzsBYYKqfQEQ2FxEnw7lAK5vF0XrxK46kDzjO9bK5X7ZyWoF+BV6pSsqVW48ePQpWSknX9M9L\nU7EVW+bR9HG2D18ppKnInZzRStBtd+7cOXVelcJdo7kMzdFyLcWYnvQs48KHxBF3zbh3qCVnl1dN\nKahqI3Aq8AjwOjBZVV8VkUtF5NBMsv2AuSLyJtAf+HW15KkW9fX1LRJm2H85kz5g92K5D97fF8W9\nmJW6F/dxRGVLyn/Dhg05H5RfgaetpFQ1TLt+/fqcPF25de/enXXr1uW9X/+afnn7ZdgcPYW4isa/\nrqvY48o6+hyiSsEdd8qgOZWCGyLJN4wTPdbY2FjyOxp1eiilgVTo+ymkFNauXZuTJq6s22tPAVWd\npqrbqernVPXXmX0XqerUzO8pqrptJs2Jqtqmgq88++yzdOnShREjRjT7tf3x5qQwCG4cs1u3buG+\nN954IyfdTTfdRF1dHePGjaN79+5le5689dZb3HPPPUB25TVjxgx69uzJv/71r5xzamtr6dSpU9ax\nRYsWAYFSU02O8fOZz3yGo48+GoAjjjiCzp07M3z4cLp27coxxxyTlfapp54Cgt7TggUL8toVTjzx\nxPB3ly5dwo/ZH3bKpxScHeTpp59OTBPHiy++mLXd1NSUM8bsV5Z9+/aNlWX48OH88Ic/BAgXzok+\nf9eL7Nq1K7BRaRQztDNlyhREhN/8Jr1H+YMPPsj+++8PwPz585k5c2ZOmvr6ejbffHMuv/xyIBiv\n79WrF6NHj059HWdvAejfv3/WMf/5psX/lpyCOPHEE7njjjuAZNuX6w3tsMMOOT2/P//5z6xdu5Zp\n06aF+1544YWiZasULW1obtM4N8lKrwqWhrgx5SibbropEMwGvuGGG4B4A9b06dOBYNWt9evX89FH\nH5Ul24wZM8Lffivo0UcfZe3ateH1HH7L6bbbbss5133MSa3XxYsXhx/lP/7xD2DjM4lWgptssgkA\nY8aMAfK34qOrprnr+66++SpPp3B69eqVmCaOuOGiZcuyTW3u+ffu3Zudd945Sz7Hq6++yl/+8heA\nsHwef/zxrDSnnHIKEyZM4IQTTgBK6yk419jzzjsv9Tmu0eC4++67c9KsWrWKZcuWhbGnFi9ezLp1\n62IbFUlcccUVicceeOCB1Pk4vvjFL4a/XcwxV8YAm222Wex5X/7yl3P2/epXvwp/L1myhHnz5hUt\nTzUwpVAGrWHGaf/+/RPlaGxsDBWGa5XFdUujLfByu65JQfhcKyo6JOBvu4VfYGOF/ZnPfCYnr7RE\nr7V+/Xq22267WI+PQvjDUo5870B08Zq0pDE8uvu64ooryrIp9O/fn5/97GdsvvnmQPMNH8U9lyjR\ncqjU9+YUZCn4cqe1D0CugX/vvffmoosuyjovabiyuTGlUAb+Q2wutzqHeyG7d++e+CI2NDTkGBLj\nXuSoUijXyOW3dP0ycvuj1/Pl98d93YfRs2fPnLzSEi2b+vp6OnfunGVnSfvsXF5pPL8gXomkIe4+\no3m4yqmmpqYopRCtnKI0l1JIY/StllLo0aNHyef6SiGtJ1Hcfv/9c/n6adqlobkjUKwXSiXxDab5\nXkT3kbuXsDl6CklKIamn4KeJ6ym4j7iUiip6zvr16+nSpUvWR1lsmJA0PQVVDe+zmj2F2traVBV5\nkqE5SilKoZQGUbTSS1PBtjalEFdxp/FYg9whX+sptBP8B33NNdcUbVAsFVXlmmuuAfK7VjY2Nub4\noZ9yyik5H/F///vfrO0PPvigLPn84aN33nkn/O2Uxa9//WvGjx8ffmD+xzBt2jRmzZoFwHXXXQds\n/Ijj7CHvv/9++PuUU07JOV5fX88NN9zAunXrWLhwIdOmTaNTp05ZH+Wnn37KokWLmDhxYt77cnL+\n73//C/cVmiMCgSF28803zylnh6py0003MWnSJH7zm9/EVjbHHntseP+qytVXXw1k9xR825av6M8/\n/3weffRRoHBPwb0vSbIuX76cSy65JGv8e+HCheHvtGFN3DN2zJ07NydNPqVQ6hoVsNGoXgq+vS1u\nnkupPYUVK1Zw6623htv+hFMI7CtnnHEG//nPf4qWuVhMKZSBX5mdc845scakavDRRx+FHir5bAr+\n8JEzsEK2IRhyKwq/0isF36PHb5n6LbTzzz8/fPGjrSvnSfTvf/8bgD59+gCBoTGKb5j+05/+lHP8\ngw8+4Cc/+QkXX3wxP/jBD4CgQvJDcc+ZM4cxY8Zw7LHH5l2wyMnp92aSyv6tt97K2l6yZAl77rln\nbNqZM2fywx/+kGOOOYbzzjsv1nHhpZdeCr1Tpk6dyh//+MdQJjfL359t68vle6e5uE9JOIWedF+P\nP/44v/rVr7KMpEcddVT4+9lnn82bv+Ozn/1s1vbnPve5nDT5lILzpiqFbbbZpuRzfRni3pV836L/\nne22227ARieEDz74IOudiX4Ty5cv5+qrr24WpxZTCmUQfQGaY7Uq2NgKvfnmm+nVq1eq4SO/co56\nskTd6Cp5H2nmAUQ/gGh4h+HDhwPxH1zacACLFy8Og6KNGzcuS0k2NDSEvaOov/nFF1/M3/72tyw5\n0wwburTu44fcAIVJ+1evXk2nTp382F/Axlb4qlWrwn1Dhgyhe/fubLXVVlllHSfXqaeeGjoc5GP4\n8OGJ74Arb1/mrbfeOvyddtipW7du7Lvvvqgqffr0yXoejnxKIe3wyj777MN+++3HhAkTANhvv/3o\n168fJ598cujAUAz+84h7t/MNH+2+++7htgtO+cgjjwDZ39zIkSNzyt/db7SHUQ1MKZRBS3kfuRev\nrq6O2traVMNHPtEPKmmCV7nyRX9H5UxSCtGPLZ+RPK2sTU1NYaXarVu3rFZb3Oxwv4yj4+xpbAou\nrTOS5yNaAaxduzbv2L8/POeHp8hX1pC+QuncuXNiubp7T/IwS/tN1NfXh7J36dKlaJtCMXYg/xm6\nIcwuXbqUZMxNereTZPb3xw1bObn8++/cuXOizaUSC0MVwpRCGbRUHKG0SsEfPvKJfoBxxthySPp4\n4zyB4vZHK0n3IcRVHGll9ZVCXV1dVqXm5+t+R8vYlzON95E7P41Rs1il4Bvy/fAUhSrntBVKvgrT\n3XuSM0Hab2L9+vWh7HGVIFRGKbiGkStPJ3c+xVcov3wypHEP93FKwbfFxCnJuOgE1cKUQhmU0lNo\namoqK5REU1NTGJ+/kFJYtWpVbOUS/QArrRT8mDb5Kip3nXJ6CsUoBTfsEh0uW79+fVgxR2WK6ym4\nD7i2tjbx+uX0FJYvXx773NatW4eqNktPIWlYLq6n4Kf1r7tmzZpEz6S1a9eGspeiFKKKOTqs48p0\n5cqViT2FUtb6KKQU8inTfErBt1PFlb+T1ZRCK0JEcgJ3FTPGvXz5ckSEmpoaDjrooJLlOOyww9hn\nn32A/ErhD3/4Aw888ACvv/56uM8ZJJ2REmDevHk5RtEnnniiZPlgo4G4V69eeSsqd11nnPQN1G4G\nNmxsbbvxV5/nn3++KJkAttpqq6xjd911VxjyeLvttgOylYKTy3mHOM+fxsZGrrvuurxjy2la51Fv\nr9dffz02BPOJJ55Ip06dGDt2bLjPyfbKK69w7733hufFvRNpXTFFJKdcH3roIUSE++67D9ioWGfM\nmMH//d//hencdS+77DJ69OjBt771rZz8VZU33ngjqyKPe47+PYhIVsV5wgkn8Pvf/x4RYejQoRxx\nxBHhsYMPPpja2lpEhLlz57JixYqwnNwkPSd/3Hedj0K9oiRD/rx580KF5GxksFEpnHbaaVnpo+Wx\nxx57ADZ81OqJehRAcjx1/8OPq9zS4rsCum5xXAXg4h75OLe/gQMHhvt8Fzf3AZe7ZoVrHQ8YMCDH\nKOsPO7g4Mq7V99xzz4XHXBiEm2++OZx9HOdO6WQ9/vjj88rUt2/fMEbVz372M4AwXEJcWA9/BvC+\n++6bJeemm27KgAEDwrT5Wrm+cfGQQw6Jla2Qm2iSG+JPf/pThg4dmrXPuYdG34lrr72W7373u3mv\n4+MqT4dTiC5siJP5n//8Z1Y6d91f/zqIbemUSFwaF7NJVWONvtF7iH5bV155JRDETnLhTQAefvjh\nrHTDhg3joIMO4oYbbgjjMx188ME510tDnJPBNttsQ21tLQMHDow1mENQmdfW1vLEE09kNbqiPUIX\nqyvpG/QdF6qFKYUyaGxszOnOJY1TVmrGs/9SFho+itKnTx/22GOP2AllEFTEe+65Z9m2kvXr1/OZ\nz3wmdkjDrwCd3O6/76boyvHoo49GROjbt29s2dbX17PXXntl+XjH0dTURENDA0cccUR4z3vuuWei\nS6/fU+jSpQsDBgzIsoF89atfzZE17nz/npKeUyFvL9dKjPKDH/wgp5Ub51J67LHH8vOf/zy1st9m\nm21y3gGXb9TmEr1+mlncLg/XK4u7XvQeILcXnnbhpWHDhtGzZ09OOeWUsJe45ZZbFjgrnrjho9ra\nWg4//HAOOuigvM9y66235itf+UqWwo02CEaPHs2QIUMS64ti42iVgimFMohWcpD8MVQqJLX/8eRT\nCkkvZ7SijrZUosdLwYWSiFMK/vWinj7+MVeO/ozsJJtCmnHWpqam2LSdO3cuqBSi14/2EPPNbPWH\nbJLKtVQX4LgeRpxSKNQTiZLPCFtIKaRpoESNpknvXDQvf/gI0iuFOPtMqWPzcUrBvdf5vp0kp4/o\ns9mwYQO1tbWJ+VRqBcJ8mFIogziXz6SPqVJKIW1PIUk5RdPHLbpSrqutq3wLKYVoT8H/QOrr66mp\nqQk/gqSKyimgQjQ1NcWmTfK0iVMKfk/Bv498PYXmVgquhZnvGRcin/eRy9fdSzSia5p3J+pzn/TO\nRfdFZzGnva+4dKWOzcfZFHwPp7j7cM4lcc8rTinU1dVl5eP3GppjQSJTChGmTJnC3//+96x9s2fP\nDn/7D2ju3Lk5H4UfdsEnKWwABC/VFVdcEa7zGsett97Khx9+mKgU3nvvvaz00Xvwz/FfbP/e4o6X\nwsMPPxwqhUcffTScIV1IKfjHXnzxxaxWUX19PX/729+ybCXLly9n5syZqT7wV155hQ8++CAn7Zo1\na8IQ6P61nO3GVwpu8lu0pxA9f/78+eHYsO+b7hv9ffyY/8UQV8m4cNAPPfRQuM95q6WlS5curFmz\nJqsh4yoj5wXzwAMPsGTJkpzw4vliQY0bN46rrroqlCfJcyopLxdC2xHXao7O1k9KF30PbrzxRpYs\nWcLixYsZMmQI/fr149577805z02Cg42hOgr1FNzM/WJ6Cv69x8lRTUwpRDjqqKNyjJa+ccc3hnbr\n1i0n9ELUk8cxbty4rG3/oT/99NOce+65XHLJJbHnrly5knHjxrH//vvT2NhI37592Wqrrdh6663D\nF37UqFGx57pY947oi+umzTvDYCWUwpIlS1i5cmVoBHXhGdzHs+uuuwLxw0duQRXIboE7Y/BZZ50V\n7nNGTmek3G+//TjnnHPCNHvttVeObNHWph+3x/HQQw+FH/KQIUOAIISEq+CdUnAzeaNxfL7yla+E\nvwcNGhS/ODfiAAAgAElEQVTKF+f9s3bt2ljXSN/DCOCCCy7ISeMbZ3faaScAzjzzzKz/7n6KwT0P\nP25VHI888kioFJyNxZ279957A7DFFlsAwYJJt956K2eeeWbYgCl2+CiKM1T77Lfffjn7vva1r+Xs\nq6mpyfquf/SjH3HMMcew55578t577/HJJ5/keE5FV/JzLs6FlIJ7lnFhMbp3784uu+wSbo8ePTpn\n+Ojwww/POa+amFIokqh/dNQbIO0wkZ+PGytN6mW4F3H+/Pk0NDRw/PHH8/777/OZz3wmbMHFxQWC\n3EVG4l7cXXbZJVwgpRJKoaamhnHjxoUVvN8jqK2tDVfZ8vc7d93zzz8/7H194QtfyMnbb/W6IQ7n\nzjd9+nSuuOIKfvvb36KqWfFxnKfTl770pYLyr1mzJhzScZWtH3rAKQXXc4hWXr6i6du3Lx9//DEn\nnHBCrPEwWtYutMWkSZOy9l922WU5xlHfhdcp9TiKHXJw77Q/hOQPcTnl6L/DrmfqymLw4MHAxjhD\ncRP+dthhB6B4pbD//vszZMiQ2PfD5/rrr0dVszzFHCLCzJkzGTNmTKicFi1alNPj9vHLY7fddgu/\n9ahSiD5n5/UXVzfU1NTw/PPPh899l112CYePovn8/ve/z3u/lcKUQpH4XdE4w2UxMzqjJH287mVy\nMdf9bmixXk3RDzB6D+UqBRcy2p8J7CoUJ3unTp0QkRxl4csA8cZA/36j4/75iC5MX+geXN6+TSNq\naE6aVOcPKbr7SirXSsXNTxsWIw1x9+VX6k7B+vfj9kWHBP1n7yjV0Ozo2rVrYggXnzRG2dra2vCd\niq5pEMUvD19mXym4fOJI+626+4oqkWIdBkqlqkpBRA4UkbkiMk9EfhlzfCsRmS4iL4jIyyJS+qyu\nCpP0AKPj3KUqBf8jK/Sy+B9Y1OOpWKUQHa906wskHS8Wv6J2ZRVX+ftd5KhnRj6lkHStQkQXpk9z\nH344DGdodkqvtraWmpoaRCTH0OwrBXd+UsVXTKiFUt2aS1UKceE/YGMPxb8f13uIGqLTKIW0hmb/\nWo2NjQUr/bRKwW905cMvgzilUMr61kkyQW5dUqzDQKlUTSmISA1wPTAGGAYcLSLRNRAvACar6s7A\nWOAGWghVTRXozP/g16xZk2OwSqsU/PFF97Enfbz+sEV9fX3BnkK+Iay6urpweKSxsZHly5fn9BSi\nrn9RVq9enVhBxSkFJ/+yZcvCfb6HRVTRud9xBuS4Md1K9xTcffhpu3TpwsqVK7M8pUSEurq6nNZ+\n3HOMUwpNTU2Jkx3jyPdc8ymMuDWf8+HKPW4VPNjYK/Cj7UZ7F66c1qxZw9q1a7O+J/fu+4bmdevW\nsWrVqqz7yKcU1qxZkxUtNo40SqGuri58P0tVCuvXr0+12FFape7yid5/e+gpjALmqeo7qloP3AEc\nFkmjgJsCuCmQa/VrBi644AI6deqU5Sny5z//ueB5L7zwQs6HmlYpfP7znw8rBDczMylERvRl9cc9\n487J93KrKgsXLmT//fenf//+vPTSSzz22GPh8aamJj766KPEymrmzJn07NkzHAKKznx1C8PPmTMn\nSynMmTOHBx98MPww/NZh0vCRX7bOGDdr1ixOP/101q1bx09/+tOs9HG48/wWu8/Xv/71nHOOPfZY\nrrrqqqy0c+bM4aOPPgpnRbvWsqoyZ86crPPjDIp1dXUsW7YsXBsC4Mgjj8xaK7qcFcHynevsIsXm\n9aMf/Sjc58dwcs/VhX+GjeXrFrF3z/aVV16he/fuWfayU089FdioXJqamli5ciW9evWiU6dOLFmy\nhMbGxnD9iyjdunVj+fLl3HnnnXnvwxm58+GHP/GjBTj8b8m3HzY0NPDvf/+b8ePH09DQQGNjY3g/\n/kRK921D8cNHUaVQzuJAxVBNpTAQmO9tL8js87kEOE5EFgDTgJ/GZSQiJ4nIbBGZnWRQLYc4I50f\nH8g9bMh+SUQka7GWTp06JbZuDjjggJx9blEUF24hqSKOVvK+a2NcwDUnw49//OOcY64S/+c//xnr\nqugMg0uWLImVJWoMj6Zz4Qb+/e9/ZykFF+bjjDPOAPIPH7nfftnedddd4e9rr702q6zydavvvvtu\n7r///qxhK59bbrkl/O1XENG0zkvLX5MBgmeeNFPYGVv9vPzWtR+a4dprr+XNN99MvA/YWKk88MAD\nOV5ue+21F7W1tWy66aZA8Jy7du3K448/ztSpU/PmG2XkyJF07tw5q8fz+c9/Pvztr59wyCGHcPPN\nNwPBLOHNNtsMyG0czZ8/nyjuXYwuuPPuu+9m9VImTZrEwoULufDCC7nvvvtSKc8BAwZw4IEHFkwX\nXbvDuRI7/EaXe9fHjx8frifhFhvq3r17eK7vWu7iZBWDP3zkK5LDDou2qatDSxuajwb+qqqDgIOA\n20QkRyZVvVFVR6rqyHLj8qTF/yC6du0aejpEK/1tt902K11STyFufDzfWLRPVCn4LVi/5RlN71dK\njrgVrnycG2nSfRQaA3fDB926dctq8bj8nJtomp6C710ydOhQxowZE25HZ3YnMXjwYA455JAwvEE0\nrd+a7N+/f9YxP63v/jly5Miw8vvc5z6XWFZ+3KNCXf+f//znsV4yPq7ntPPOO+esHtapUydOOOGE\nMAxCXV0dxx13HF/96lezlGsaampqOOqoo2Lj/ABZLpQXXHAB3/ve94Dg2frj7D5xbrfuG/OVDATv\nr1+mY8eOZYsttuDSSy/l0EMPzUp78sknx95DqUEno3LHPdt99903Z6ho0KBB9OnTJyfsdSl2AP+7\n8XvLSXGVKk01lcKHgO9DNyizz+cHwGQAVf0P0BXYnFZGQ0NDjiFtw4YNqGrOWHi+ae5R0oxF+9d0\n+C9a3DlOKcSNqRYy3hYaFy3kLeM+/q5du2b1FKJG4TQ2hais/geSVik4koaPfKLH/PLzZSnFW6sS\n48Gu1ZjUePAVbVywxmLIF4o77llBtodWGqXgiNqONmzYkLfxkWYYptQIAoXCygNZvSgnS9LaEP47\nVIpNoVz38FKoplKYBWwrIkNEpDOBITnaj/0A+CqAiHyBQClUfnyoTBobG3OUQtws3GKVQvTFT7IF\nRPf714yrIFz6Uqb3F/KgKNRTcN3tbt26ZSmFaCiLfD0F9zsqa9Jyk2kqP1dO+dJGy8v/iH1ZSvHW\nqqSRMKnxUEmlEL0v/7f/zkWN8UkLJ+VbNjWq/Dds2FCSq26hpTLTEH2/455tly5dcvJPWkWuFPdx\n/xss15OpFKqmFFS1ETgVeAR4ncDL6FURuVREXB/wDOCHIvISMAn4rlYqnGiZuAknEHxgzq7gewJB\n9kdRU1PD//3f/zFw4MCs6fZLly5l+vTpOde47LLLsj7wWbNmxb44SSuRQXwF4WwF5fQURowYwW23\n3ZZzvNDC4W6su2vXrmHlcfHFF4eGe5d/TU0NTz31FIsXL+b222/n7bffDvNwH1xU1k8//TT87Q/b\npfEycbLk88SJKoUkxVNuT6HUV7yQl5qryNeuXcvy5cvLUgr19fUsWrQo/A4mTpwYHvOvHy2XRYsW\n0dTUlGOf8W10UaLKf/LkyfziF79ITF/I8w1KVwrR2d++3cfRuXPnHBl899pZs2Yxa9YsHnjggZwQ\nKGlw7+GECRN46aWXij6/XKpqU1DVaaq6nap+TlV/ndl3kapOzfx+TVX3UtWdVHWEqj5aTXmSiBqX\nfJxfenRyjq8Uxo8fz+jRo0Pj58KFC7PCWjiPDIfzSLj//vtzrhdnSI8qBT9Wzje+8Q0ge1zWxVmK\nM8jFfVDXX399+Nv/yE844YSctIV6Ci7cwfjx47MqD1dJuPyXLl1KQ0NDbAgGZ3CNDjm4WP5R0vjh\nn3baaQwdOjRLmTiuvvpqhg8fnjP27mI2QbBokcO3L8QpBTeu//3vfz/c98ILL4S/XcgOVxb53j+f\n66+/noEDB8bakWCjUnAzxn0HiWJxi7ycd9551NfXhw2NQYMGMXr06KxrOtz7H/ecfAM7kGU/ic7U\nvu6668L1NApNYPS56qqrwt9x724c0TAwUX7yk58A2R5lAwYMCO0oDmeP+vTTT+nUqROjRo0Kv03H\nSSedlEomN9N7woQJYbiQ5qSlDc2tgqjRzsd98PmUwrnnnsuMGTOyFjHxF9XxPWVUleOOOy7xenHd\n5qhScIu+QPCCjho1Ksso62SLW5Aj+gGOGDEiy0upUOuyUHfWGdv23HPP2OMufxdXJu5+nUF5++23\nz3stSDY0RvnGN77B22+/HRtH//TTT+ell16irq4uy5Dpx07yvcecBxXEK4XBgwfzzW9+Myvmjr8Y\njku/5ZZbctxxx3H77benuoejjjqKBQsWJD4jpxSc4o5zt02Le+ec8oagMTN//ny+/OUvh55Dviw7\n7rgjQN75A643/OGHG82LcYra4VycfZxSmDBhQlaDwCnb22+/PWu9i3zEKY+bb745q2cEGxtDf/zj\nH+nVqxennHJKlquvq8hdfLIo/fr1C9MUYsSIEVkxwICs1e2qjSkF8vv1p1EKjqTxw2jLJt8QRpq1\naqPEzVKG+FZWtEIpdip9obHeQmPZ0bAP+fKLyh/XQqy077ZfHkkt0kLDR3Fl4MsZnQlbKdx7UMxM\n7yRcOXTq1ClvfnHDatGgg1EZ8+URJV9PIdpDdG6ixayVEPct1tXV5cgUVwZxzgf51qIohug9NNfE\nNTClAFROKaR9cPmGO+JeqEIzLaNKIRqv3qdcpVDohS+kFHzvIzdDO4l83keOaiqFJPwx8LRKwQ9e\nlzQ/o1yqoRREJDY/fxKiwz2vfD2FuPvN10jKN6s9+h25HnkxSiFp9nk5SqES8ayi991cIS7AlAKQ\nvyXujqXxPkp6cO6FShP337V2fNIohWXLloUfi8sj7nqFlEKhly/OtTAapK4YpeAPI0SJytLcSiFJ\nefuVQW1tbZYBHIIyisruP4vFixezfv16li1bVtEWoLume0aVUAqqGr5PhfJz91hsTyEfxVTw0fAZ\naUjqKURXAYxTCtHGgduXz/02LdH7bo4V1xymFMgfktaFlHAVhFtrwY05+i3ApBfeGU7dWrv5Xto9\n9tgjyxMHCiuFJ598khdffJEf/vCHwMZQ0nGGxuiHHR37jxqn3YzPxYsXIyLh2gg+viIrZvho5cqV\nsTM+nY0nKn/cGHk+e1ApuDAWkGvTcDYav4xEhPfeey8M093Y2MjChQtzntnAgRsn848ePZquXbuy\ndu3acDZwJXAxq44++migPKWwzz77AMG75SY8+vm5CWz+u+zKxV0/jmKVQtyMfVeWffr0yZqM6ewP\nxYQLicu/rq4uK4+uXbsyfvz48JjDX2DI1Q89evSInb298847p5YJcocu87n0VhwXx7ut/O26665a\naQhiMOldd92lv/71r8NtVdUnn3xSAb3hhhuy9p9zzjkK6Jo1a8J8Lr744jBNnz59wv2nn366Arp8\n+fKca8b93X///VnyTZ8+PZRh3rx5ifI72Xr06KHDhg2Lvdd58+ZlpV+6dGnW8aampqzjs2fPVlXV\nmTNnZu3/y1/+orW1tQrohx9+GJ5//PHH6+DBgxPv03HeeeeF+0aMGKHz588Pjy1dulQnTZqkDQ0N\nWbJ9/PHH4Tk1NTX685//XJuammLvs1RWrlypU6ZM0UmTJunixYuzjr333ns6derUrH3Tpk1TQCdO\nnKiqqitWrFBATz/99Kx0jY2NuuOOO8Y+70pxyimnZOUb966kZcmSJTly3nrrreHx5cuX61NPPZV1\nzurVq7PST5kyRZ977jm97bbbwn3vvvtu7PVmzJihL774Ytb5kydPjk27YsUKnThxoq5bt04bGxv1\n7rvvzjov+t4U4swzz9S///3v4fkPPfSQ1tfXxz6rKVOmhOfFPcMPPvhAv/nNb2Ydmzp1ata3n4a7\n7rorK4977rmnqPPjAGZrijrWegoeRx55ZLjYjMN1G6PhNdavX0+vXr2yWrNxS026tJtttlneaeq+\nZ0LSYuhf/OIXC4apgEDR+yEhfKIttah7Y5qF2Lfddlu+//3vh3MPojNf07QG/TRnnXUWgwYNypJp\n7NixOfn4rqBvvvkm1157bcXXrO3ZsydHHHEEY8eOzQn2t/XWW+e4GbrehL/WgkvrU1NTk+UyWQ2i\nvZNyhhz69u2b4xXkP49NNtkk7E04unfvnjXs4Tzjvv3tb8fm4TN69Gh22mmnrOGco446KjZtr169\nOProo+nSpQs1NTUcfvjhoXfYpptuWnRv5He/+x3HHntsGN/Jj3gaJS4ci8+WW26Z40Z6wAEHFB2i\nIvpd+iMS1caUQh7UW2wlOpQRt5ZC0mLuaRaXzzdLOV/YijjyDeEU+8G4+1evOxudHewrjrQzacsd\nS29Ow1s+omsPpPXUqQZRm0uxIbOjROUt9rnGhRYp9NxKfa5+GO5SSTPrPcmmECeLoxi7SFIe5T7L\nYjClkIeGhoa8SiH64PwXxi3IkpQ2Sr54RsUoBafIkl5sP+80reyoYd2XIy4kRilKoZTWfnMa3vLh\nnqsphdw07v33n28lVkuLo9j1MuIoNj5W0jcdVQKlPIdoHpXuEeejQyuFdevW5SzO7dPY2BgOkfhK\n4YUXXuCmm27KCpEL2Q9fVcM1B2699dai/P8vuugihg8fnrVMIKT7YNws3DShF9K8rGPGjGHy5MlZ\nFb97QeNWiJo2bVrJlUcxtBal4D7eZ599lquvvjosi2L98StBtBxbQin4M5fjnmsp3m1pcBX0okWL\nSjofsj3jIN6zrRSlUArRvE0pNBPPPPMM9957b85+90AaGhp4+OGHgWyl4BZ/j47h5nOvdGsnJOFC\nU0Aw6/OVV17hueeey7pO0gflh71wnlRJMfT79esXeuy4xdajnH322aHtYt26dXznO98JQzcAnHnm\nmVnyOIXhein+ym1Jtg3fGyNurYkkxo8fz84770zfvn1Tn1NNnJfK7bffzhlnnBGujRFXgcaF2fjN\nb35TMVmiYRTKDTMfXd/Dt/ukwV9A6NBDD2XUqFGx3j6VoNAqbGm48MIL2X777RkyZAiQvdaGw39+\nznMsWu6VcJOO2qTiohNUjUKWaOBO4OuApLFcV/uvkt5HznME0AMPPDDc/4c//EEBXbx4cXj8tdde\nK+g5ctpppymgZ599dk66Aw44ICut27/XXnuFv1944YWsc6ZPn66qGz0RXn755cR7+fa3v62f//zn\n9dhjj1VAhw4dWlbZzJo1K0uWOXPmKKD33ntvmOb+++9XQGfNmqWqGnpsXH755Vl5rV+/Pra84va1\nRXr37h3ei/NSu+OOOxLTu7Rvv/12xWW57LLLKlauZ511VtY74HvaJeHSbr/99iVd052/cOHCos67\n8sorq/I+7bnnnmG+vXv3TnWO/x2XU1/169dPAZ0xY0bJefhQQe+jW4DvA2+KyOUiUlnH8FZI3JoC\nabrObkw3bn5AUpfS94eOXiO6dmy+IRM3m7VYo3QSUVlcb8DPN9pTSBo6ac4p+i2B/2zdMGCae67E\nMEOUSk7mi8pXjLylRikt5VqlpE+LPwSX1gjuy1LOEF4aw3c1KCixqj6sqt8hWHP5I2C6iDwlIseL\nSOtwASmRpElhcUohzQvh8otzH0t6aeNmRTrc9dNU9HV1dVlKoVzvnOj5cTJEbQpJRtbmHA9tCfxn\n6AzOaT7kYmbepqWSlWNUvmIaGuUqhWLLphplCclhwtPKUs6732qVAoCI9AGOAY4HXgb+DOwJPFw9\n0aqPb9xVzyjmHoK//nAaje8+hLjWWtIHFQ2u5hNdsCRNT8GdU25PIY1ScPK6sedKxNxpi/j360JM\nt1RPoZIKuJyKtrmVQmvqKfiyt8uegojcBfwH6AscoaoHq+rtqnoKsFm1Bawmftx3f91Z9zD8fWkm\nj7jJL249YJ9okCxnSPLD70av4RbqdgbhfPHxa2tr+fjjj7nvvvty8i2F6AfgZPFlcArikEMO4f77\n7y+oFOLWIHZGvbaMXwG6tTLSVAbV+Nij60yXg1swqRRKWVwG4Mtf/jJQmXAYlcA3lseFr4jDHxIe\nPnx4ydceNWoU0LwT14BUhuYDaCVGZq2wofmaa65RQE877TRdtWpVuH/u3LmxBuUHH3xQAe3fv78C\net1112Xlt3btWr3vvvu0sbFR//rXv+qYMWPC87/3ve9lpX3rrbf06aef1g0bNuiZZ56pixYtUlXV\nr3/96znXPfzwwwsa0E499dSs8z755JOyyub999+PNaz7IQSefvrpcP+PfvSj8JybbropJ79//etf\nOnfu3Kx9M2fOLCsUQ2thxIgROeX0/vvvJ6Z/5plnKhK2II76+no988wz9Y033ig7r6997Wvh/Tzz\nzDOpzrnqqqvKMvguXLgwdLAohjVr1ujll1+uzz33XEnXTWLp0qWJjiX5mDZtmv7973/XdevWlXzt\njz/+WP/xj39ULJQLKQ3NaZTCyUBvb7sPcFKazKvxV0ml8Nvf/lYBXblyZdb+RYsWJXoZ7bbbbrrF\nFlukjkdyySWXKKAXXnhhKpnuu+++nOsefPDBussuu+Q9z3k+ub+1a9emul4SH374YU4ZRL0vZsyY\nkaUU3n77bQX0r3/9a1nXbmt8+9vfzimraNyktoh/X2nxvdbaC7vttlu7uKe0SiHNgNfJqhrOSFHV\nT4FTUpyHiBwoInNFZJ6I/DLm+DUi8mLm700RWRaXT7VIGu7IN55ZV1cXTrBJ08XVjK0i7dhi3LWL\nnRHt5CyHuHsrtL6B2RQ2Ui3DZ3NSil2qPdx3lNYSUqW5SHO3WW+GiHQCCn71IlIDXE8w/LQAmCUi\nU1X1NZdGVU/30v8UKC6+bJkkVWL5jFZ1dXXh5Kxi3FTTGgDjrp0mdlJUlkobmiH3g4+uUmZKYSPV\nMnw2J6VUhu3hvqN0NKWQpvn6mIhMEpF9RWRf4HYgd+HUXEYB81T1HVWtB+4ADsuT/mhgUop8K0Zj\nYyMiktOKL9RTcB4+zdFTEBFmzJhRdE+hXOIquqihLdpTcMbFjqYU0vSq2iLWUwgo15OqrZGmpjoL\n+DdweubvGeDMFOcNBPxaZEFmXw4isjUwBHgy4fhJIjJbRGYvXrw4xaXTkRS8LfqR+wuh+Iu6pKmI\nv/Wtb7HjjjvmhFxOIsl7pFCYjHwB9UohzUIlu+++e9Y133//fSDey6g9E/cOtYe5Geeccw4AN9xw\nQ+pzPvvZzzJy5EiuueaaaonV7LjQJR2FgrWaqm4A/pj5qxZjgSmZa8XJcCNwI8DIkSM1Lk0p5Ivo\n+cILL4Txeb73ve+F+8866yz+9Kc/AelaxLvssgsvv/xyapmS4tX4K4LF4csStzpasXTq1InRo0fz\n1FNPJabp1asX3bt3D4fTXA/KueZ2FNprz2j77bfPmr+Thq5duzJr1qwqSWQ0BwWVgoh8Dvg1MAwI\nZ2Wp6nYFTv0Q2NLbHpTZF8dY4CeFZKk0acM8+/jd42qMNSZ12QsNPxVa/KMU0txfly5dcpRCexg6\nKYb2qhSMjkma4aO/EsQ/EmAMMJkgSF4hZgHbisgQEelMUPHnhO4Uke0J3Fz/k1LmipFPKSS1kKKL\ntleaJKVQqMVWDaWQZkzZlUdTU5MpBcNoB6RRCt1V9REAVX1bVS8gUA55UdVG4FTgEeB1YLKqvioi\nl4rIoV7SscAdWmw/tQKsW7cuseJLiotkSiEb14NZvXp12GNoLWsdNBemFIz2RBqlsD7jhvq2iJws\nIt8AehU6CUBVp6nqdqr6OVX9dWbfRao61UtziarmzGFoDl555ZXYNYgBevfuHbvfVwppjLHFkqRo\n/MVL4vDvo1JypQmVscceewAwceJEZsyYUZHrtjWi3imbbrppC0liVAO3tkgx6360ZdIohdOBHsDP\ngL2AEwlCabd5+vXrl+hCt8022/DXv/6VefPmZe3v1q0bt99+O7fffnv4slQSt1JblEIrqfmL2u+4\n444VkeXyyy/PMjRPmDAhJ81tt90W/u7Xr1+iMm3PuHg9AH/605/4z3+afSTUqCL//Oc/+cUvfsHk\nyZNbWpRmIe/4R2YC2rdU9TlgJUGU1HZDQ0NDzgpHPuPGjYvdf8wxx1RLJACOP/54JkyYwPPPPx/u\nK+Qr3adPHyDw/qiUO2RtbS377LNPuB3Xc/B7JQ0NDTkri3UENttsY1zIH/3oRy0oiVENBg0axFVX\nXdXSYjQbeXsKGRfRL+dL05YpxfuouYhW7IWUguvxVHOiTSEPqMbGxlZbntWko9lQjPZNGkvp8yJy\nD3AXsNrt9O0CbZWGhoaq2AUqQVQpFDI0O1tHC9jrQxobGztcSAAoL2a+YbQ20nzBvQiUwUHePiXG\nvbSt0Zp7Cv/73/+ytgu1Rp1SKGR7KIdCw1KLFi1i4MDYSevtmo6oCI32S5oZze3KjuDTmlu2K1eu\nzNp2IQeS6NUrlUNYSRxwwAE89thjBRcMmTt3LoMHD66aHK0Vt1DQN7/5zRaWxDDKJ82M5hvj9qvq\nSZUXp3lpzT0FZxt477338hrDHX379q2aLI8++mje44MGDWLBggVAx2w1d+7cuUWH7QyjkqT5gp/w\nfncFvkV2oLs2S2tWCm7yXNqoky05i7jaoT8Mw2g+0gwfZYW0EJHbCCKltnlas1JwPYW0lX1Lhizu\n2jUMidVqy9MwjHSU4jYxBKjc6uAtyJIlS1ptJeZ6CmmVQmvpKZh7pmG0bQoqBRH5VESWZv6WAY8B\n51ZftOqyYMECVqxYEQZxa23svffeQPrK3g3btMRUfF/GO+9MEyvRMIzWSpoB4M29300tEbiuGrjF\nekaPHt3CksRzzz338Pbbb6dWCiLCs88+y9ChQ6ssWS7mp28Y7Yc0X/PBQE9V3aCqKiK9ReSQagtW\nbVwAudbqV9+rV6+CC+tE2X333RMX6akm7WGVMcMwAtIohUtVdbnbUNVlwGXVE6l5cErBvGXKx5SC\nYeRpQGAAABQnSURBVLQf0iiFuC++zdekTimYYbR8TCkYRvshjVJ4QUR+KyJbZ/5+B7xQbcGqjfPu\nsZ5C+bRWDy7DMIonjVI4NZPuPuBegrhHP66mUM2BDR9VjvPOOy/8/fvf/74FJTEMo1zSTF5bBZzZ\nDLI0K6YUKsdXv/pVC/NgGO2ENPMUHhaR3t52HxF5ME3mInKgiMwVkXkiErvkpoh8W0ReE5FXRWRi\netHLw5SCYRhGLmlqxP4ZjyMAVPVTERlQ6KTMqm3XAwcAC4BZIjJVVV/z0mxLMBFur0y+n4nPrfKY\nUjAMw8gljU2hSUQGuQ0R2Spl3qOAear6jqrWA3cAh0XS/BC4XlU/BVDV/9FMmFIwDMPIJU2NeBHw\nLxF5ksA9dT/SGZoHkh1NdQGweyTNdgAi8i+gBrhEVR9OkXfZmEuqYRhGLmkMzQ+KyCjgS5ldZ1ew\nRV8LbEugaAYBT4nIjv5wFYCInAScBLDVVmk7KvmxnoJhGEYuqYLWqOrHqnov8CLwAxF5KcVpHwJb\netuDMvt8FgBTVbVBVd8F3iRQEtHr36iqI1V1ZKXCONg8BcMwjFzSeB/1F5Gfish/gDeA7sB3U+Q9\nC9hWRIaISGdgLLnrOt9L0EtARDYnGE56J7X0ZWA9BcMwjFwSlYKIfF9EHgP+TWAf+AmwSFUvVNWC\nM5pVtZFg4tsjwOvAZFV9VUQuFZFDM8keAZaIyGvAdOAsVV1S3i2lw5SCYRhGLvlqxD8TKIQjnRIQ\nkaJmKKnqNGBaZN9F3m8FfpH5a1ZMKRiGYeSSr0YcCHwbuE5E+gB3Au0myI0pBcMwjFwSh49U9X+q\nep2q7gWMAdYRDPW8IiKXNpuEVcJcUg3DMHJJ6330vqpeqaojgO9UWaZmwXoKhmEYuRRdI2bCVFxU\nMGErx1xSDcMwcumwi+uuXr0aMKVgGIbh02GVwvjx4wFbdN4wDMOnYDNZRIbH7F4OzFfVpsqLZBiG\nYbQUacZO/gKMAF4lCIj3BeA1oJeInKSqT1RRPsMwDKMZSTN28h6wq6qOUNWdgF0JYhR9HbiqirIZ\nhmEYzUwapfAFVX3ZbajqK8AwVZ1XPbEMwzCMliDN8NEbIvJHgkVyIJin8IaIdAEaqyaZYRiG0eyk\n6SmcQBDi+peZv4XAOAKF8NXqiWYYhmE0N2kW2VkDXJn5i7K84hI1E/vuuy9BPD7DMAzDkcYldQ/g\nYmBrP72qbldFuarOhg0b6Ny5c0uLYRiG0apIY1O4BTgbeB7YUF1xmo/Gxka6devW0mIYhmG0KtIo\nhRWqen/VJWlmNmzYYBFSDcMwIqRRCk+KyG+Ae4D1bqfvptoWMaVgGIaRSxqlsHfkP4ACoysvTvNh\nSsEwDCOXNN5H+zSHIM1NY2OjRUg1DMOIkFgrisjRqjpJRH4Wd1xV/1AocxE5EJgA1AA3qeoVkePf\nBX4HfJjZdZ2q3pRS9rKwnoJhGEYu+ZrKfTL/+5WSsYjUANcDBxBMfpslIlMzi/T43Kmqp5ZyjXIw\npWAYhpFLolJQ1Rsy/y8sMe9RwDxVfQdARO4ADiOIsNqiNDU18dZbbzFq1KiWFsUwDKNVkWby2ubA\n94HBZE9eO6nAqQOB+d72AmD3mHRHiMhogsirp6vq/GgCETkJOAlgq622KiRyQT755BMgUA6GYRjG\nRtLEProP6A88Azzh/VWC+4HBqjoceAz4W1wiVb1RVUeq6sh+/UoazcqioaEBgP3226/svAzDMNoT\nadxveqjqGSXk/SGwpbc9iI0GZQBUdYm3eRPw2xKuUzROKdTV1TXH5QzDMNoMaXoKD4nI10rIexaw\nrYgMEZHOwFhgqp9ARLbwNg8FXi/hOkVjSsEwDCOeND2Fk4FzRGQNUE+wJKeqat98J6lqo4icCjxC\n4JJ6s6q+KiKXArNVdSrwMxE5lCAM91Lgu6XfSnpMKRiGYcSTRilsXmrmqjoNmBbZd5H3+1zg3FLz\nL5WrrgpWEZ03zxaPMwzD8Mk3eW1bVX0L2CEhSZuNffTggw8C8MEHH7SwJIZhGK2LfD2FXwI/IJiA\nFqVNxz5qbAxWEbXhI8MwjGzyTV77QeZ/u4t95GwKFvvIMAwjm1S1oohsDwwDurp9qjqxWkJVGzM0\nG4ZhxJNmRvMFwNeA7Qk8ib5OMJGtzSqFtWvXAtZTMAzDiJJmnsJ3gC8Di1T1eGAnoEdVpaoyP/7x\njwE4++yzW1gSwzCM1kUapbBWVTcAjSLSC/gI2Lq6YlWXPn36UFNTQ58+fQonNgzD6ECkGT95QUR6\nAzcDs4EVwMyqSlVlbIEdwzCMePLWjCIiwCWqugy4XkQeATZR1TnNIl2VaGhoMKVgGIYRQ96aUVVV\nRB4DvpjZbhdTgBsbG83zyDAMI4Y0NoUXRWTnqkvSjNjwkWEYRjz5wlzUqmojsDPBUppvA6vZGBBv\nl2aSseLY8JFhGEY8+WrGmcAuBCGt2xU2fGQYhhFPPqUgAKr6djPJ0mzY8JFhGEY8+WrGfiLyi6SD\nqnp1FeRpFmz4yDAMI558NWMN0JNMj6E9YT0FwzCMePLVjItU9dJmk6QZMZuCYRhGPPlcUttdD8Fh\nPQXDMIx48imFr5abuYgcKCJzRWSeiPwyT7ojRERFZGS510yD2RQMwzDiSVQKqrq0nIxFpIZg1bYx\nBGsxHC0iw2LS9QJ+DjxXzvWKwYaPDMMw4kkzo7lURgHzVPUdVa0H7gAOi0l3GXAlsK6KsmTxySef\nWE/BMAwjhmoqhYHAfG97QWZfiIjsAmypqg/my0hEThKR2SIye/HixWUL9tFHH7FixYqy8zEMw2hv\nVFMp5EVEOgFXA2cUSquqN6rqSFUd2a9fv7Kv3bNnTwYMGFB2PoZhGO2NaiqFD4Etve1BmX2OXgTR\nV/8pIu8BewBTm8PY3NjYyGabbVbtyxiGYbQ5qqkUZgHbisgQEekMjAWmuoOqulxVN1fVwao6GHgW\nOFRVZ1dRJsAMzYZhGElUTSlkIqyeCjwCvA5MVtVXReRSEWnRIHvmkmoYhhFPVWtGVZ0GTIvsuygh\n7X7VlMWnoaHBegqGYRgxtJihuSUxpWAYhhGPKQXDMAwjxJSCYRiGEdLhlEJTUxNNTU1maDYMw4ih\nwymF+vp6AOspGIZhxNDhlMKTTz4JgKq2sCSGYRitjw6nFFatWgXAoYe26FQJwzCMVkmHUwqNjY0A\ndO3atYUlMQzDaH10OKXQ0NAAYIZmwzCMGDqcUnA9BTM0G4Zh5NJhlYL1FAzDMHLpcErBho8MwzCS\n6XBKwYaPDMMwkumwSsF6CoZhGLl0OKVgw0eGYRjJdDilYD0FwzCMZDqsUqipqWlhSQzDMFofHU4p\nuKU4RaSlRTEMw2h1dDil0NjYaENHhmEYCVRVKYjIgSIyV0TmicgvY46fLCKviMiLIvKMiAyrpjwQ\nKAVzRzUMw4inakpBRGqA64ExwDDg6JhKf6Kq7qiqI4DfAldXSx6H9RQMwzCSqWZPYRQwT1XfUdV6\n4A7gMD+Bqq7wNnsAVV/k4F//+le1L2EYhtFmqWaTeSAw39teAOweTSQiPwF+AXQGvhKXkYicBJwE\nsNVWW5Ul1CabbMKaNWvKysMwDKO90uKGZlW9XlU/B5wDXJCQ5kZVHamqI/v161fW9RobG9lzzz3L\nysMwDKO9Uk2l8CGwpbc9KLMviTuAb1ZRHiBwSTVDs2EYRjzVVAqzgG1FZIiIdAbGAlP9BCKyrbd5\nMPBWFeUBTCkYhmHko2pKQVUbgVOBR4DXgcmq+qqIXCoiboHkU0XkVRF5kcCuMK5a8sybN49bbrmF\nOXPmoFp1e7ZhGEabRNpaBTly5EidPXt20eedeuqpXH/99eF2W7tvwzCMchCR51V1ZKF0LW5obi5G\njBjR0iIYhmG0ejqMUvjsZz/b0iIYhmG0ejqMUjAMwzAK02GUgtkQDMMwCtNhlIK5oRqGYRSmwyiF\n/fbbL/y90047tZwghmEYrZgOoxS6du0a/t5rr71aUBLDMIzWS4dRCj6dO3duaREMwzBaJR1SKZh9\nwTAMIx5TCoZhGEZIh1QKe+yxR0uLYBiG0SrpkEphn332aWkRDMMwWiUdUinU1NS0tAiGYRitElMK\nhmEYRogpBcMwDCOkQymFAQMGAKYUDMMwkqhtaQGak7vvvpuHHnqI2toOdduGYRip6VC14x577GHu\nqIZhGHmo6vCRiBwoInNFZJ6I/DLm+C9E5DUReVlEnhCRraspj2EYhpGfqikFEakBrgfGAMOAo0Vk\nWCTZC8BIVR0OTAF+Wy15DMMwjMJUs6cwCpinqu+oaj1wB3CYn0BVp6vqmszms8CgKspjGIZhFKCa\nSmEgMN/bXpDZl8QPgIfiDojISSIyW0RmL168uIIiGoZhGD6twiVVRI4DRgK/izuuqjeq6khVHdmv\nX7/mFc4wDKMDUU3vow+BLb3tQZl9WYjI/sD5wL6qur6K8hiGYRgFqGZPYRawrYgMEZHOwFhgqp9A\nRHYG/gwcqqr/q6IshmEYRgqqphRUtRE4FXgEeB2YrKqvisilInJoJtnvgJ7AXSLyoohMTcjOMAzD\naAZEVVtahqIQkcXA+yWevjnwSQXFaQ9YmeRiZZKLlUkuba1MtlbVgkbZNqcUykFEZqvqyJaWozVh\nZZKLlUkuVia5tNcyaRXeR4ZhGEbrwJSCYRiGEdLRlMKNLS1AK8TKJBcrk1ysTHJpl2XSoWwKhmEY\nRn46Wk/BMAzDyIMpBcMwDCOkwyiFQms7tCdE5GYR+Z+I/Nfb11dEHhORtzL/+2T2i4j8IVMuL4vI\nLt454zLp3xKRcS1xL5VCRLYUkemZ9TteFZGfZ/Z32HIRka4iMlNEXsqUya8y+4eIyHOZe78zE5EA\nEemS2Z6XOT7Yy+vczP65IvL1lrmjyiAiNSLygog8kNnuWOWhqu3+D6gB3gaGAp2Bl4BhLS1XFe93\nNLAL8F9v32+BX2Z+/xK4MvP7IILotALsATyX2d8XeCfzv0/md5+WvrcyymQLYJfM717AmwTrfHTY\ncsncW8/M7zrgucy9TgbGZvb/CTgl8/vHwJ8yv8cCd2Z+D8t8U12AIZlvraal76+McvkFMBF4ILPd\nocqjo/QUCq7t0J5Q1aeApZHdhwF/y/z+G/BNb/+tGvAs0FtEtgC+DjymqktV9VPgMeDA6ktfHVR1\nkarOyfxeSRB6ZSAduFwy97Yqs1mX+VPgKwSLXkFumbiymgJ8VUQks/8OVV2vqu8C8wi+uTaHiAwC\nDgZuymwLHaw8OopSKHZth/ZIf1VdlPn9EdA/8zupbNptmWW6+TsTtIw7dLlkhkpeBP5HoODeBpZp\nELsMsu8vvPfM8eXAZrSvMrkWOBtoymxvRgcrj46iFAwPDfq4HdIXWUR6AncDp6nqCv9YRywXVd2g\nqiMIQtuPArZvYZFaDBE5BPifqj7f0rK0JB1FKaRa26Gd83Fm+IPMfxeqPKls2l2ZiUgdgUK4XVXv\nyezu8OUCoKrLgOnAlwiGytxaK/79hfeeOb4psIT2UyZ7AYeKyHsEQ8xfASbQwcqjoyiFgms7dACm\nAs5TZhxwn7f/hIy3zR7A8sxwyiPA10SkT8Yj52uZfW2SzFjvX4DXVfVq71CHLRcR6ScivTO/uwEH\nENhapgNHZpJFy8SV1ZHAk5ne1VRgbMYbZwiwLTCzee6icqjquao6SFUHE9QRT6rqsXS08mhpS3dz\n/RF4k7xJMGZ6fkvLU+V7nQQsAhoIxjN/QDDW+QTwFvA40DeTVoDrM+XyCjDSy+f7BEayecD3Wvq+\nyiyTvQmGhl4GXsz8HdSRywUYDryQKZP/Ahdl9g8lqMTmAXcBXTL7u2a252WOD/XyOj9TVnOBMS19\nbxUom/3Y6H3UocrDwlwYhmEYIR1l+MgwDMNIgSkFwzAMI8SUgmEYhhFiSsEwDMMIMaVgGIZhhJhS\nMNo9ItJfRCaKyDsi8ryI/EdEvtVCsuwnInt62yeLyAktIYthxFFbOIlhtF0yk9buBf5/e/cPUmUU\nh3H8+0OzskCH2oKkocUIw4qkIsO9gpr6Q3+kQUJo0iWwJWgohUSwJbBNaqopgkiKqEhpcailPwQN\nFhblkCBPwzn3+hZalN3l9nwWr+d973uPF+57Xn/vPc8ZkXQ4t60H9lXwNWs1n5Xzs3bgK/AIQNJw\npfph9jc8T8GqWkR0kCZl7VlgWw1wkXSiXg4MSboaEe3AeeADsAkYB45KUkS0Av3A6rz9hKT3EXGf\nNCFuF2ny4EvgHCmq/SNwBFgJPAbmgCmgG+gAvkq6FBEtpGjmetLEp1OSpvOxnwB7gUagU9KDf/cu\nmc1z+ciqXTMwsci2TlJ8xTZgG3A6xxJASlE9S8rG3wDszNlJg8AhSa3ANeBC4Xh1krZKugw8BHZI\n2kLK0emR9Jp00h+Q1LLAif060CtpM2kWdV9hW62k7blPfZhViMtH9l+JiCHS1fws8AbYHBGlXJsG\nUk7NLPBU0rv8nOdAE/CJ9J/D3VSVooYUJ1IyWni8DhjNIXt1wKvf9KsBaJQ0lptGSBEKJaUAv/Hc\nF7OK8KBg1W4SOFj6RdKZiFgDPAPeAt2Sfgi0y+Wjb4WmOdJnJYBJSW2LvNZM4fEg0C/pVqEctRSl\n/pT6YlYRLh9ZtbsHrIiIrkJbff55B+jKZSEiYmNErPrFsV4AayOiLe+/LCKaF9m3gfm45OI6zl9I\ny4H+QNJnYDoiduemY8DYz/uZVZqvOKyq5ZvDB4CBiOgh3eCdAXpJ5ZkmYCJ/S2mK+aUWFzrWbC41\nXcnlnlrSSl2TC+x+HrgREdOkgal0r+I2cDMi9pNuNBcdB4Yjop609vPJP/+LzZbG3z4yM7Myl4/M\nzKzMg4KZmZV5UDAzszIPCmZmVuZBwczMyjwomJlZmQcFMzMr+w4QZVD1HZE8lQAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05041e2978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for ix, t in enumerate(vocab_processor.fit_transform(texts_test)):\n",
    "    y_data = [[target_test[ix]]]\n",
    "    \n",
    "    if (ix+1)%50==0:\n",
    "        print('Test Observation #' + str(ix+1))\n",
    "        \n",
    "    [[temp_pred]] = sess.run(prediction, feed_dict={x_data:t, y_target:y_data})\n",
    "    \n",
    "    test_acc_temp = target_test[ix]==np.round(temp_pred)\n",
    "    test_acc_all.append(test_acc_temp)\n",
    "\n",
    "print('\\nOverall Test Accuracy: {}'.format(np.mean(test_acc_all)))\n",
    "\n",
    "plt.plot(range(len(train_acc_avg)), train_acc_avg, 'k-', label='Train Accuracy')\n",
    "plt.title('Avg Training Acc Over Past 50 Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
